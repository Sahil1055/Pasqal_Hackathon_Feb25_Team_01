{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "n_clinical = 38 \n",
    "n_image_nodes = 6*6\n",
    "n_nodes = n_clinical + n_image_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples:  84\n",
      "Test Samples:  21\n",
      "Train labels shape: torch.Size([84])\n",
      "Test labels shape: torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "# Load Ground-Truth Values\n",
    "train_labels = pd.read_csv(\"data/labels/train_labels.csv\")\n",
    "train_labels = train_labels.iloc[:, 1].tolist()                 # (n_train,)\n",
    "test_labels = pd.read_csv(\"data/labels/test_labels.csv\")\n",
    "test_labels = test_labels.iloc[:, 1].tolist()                   # (n_test,)\n",
    "\n",
    "n_train = len(train_labels) # 84\n",
    "n_test = len(test_labels)   # 21\n",
    "\n",
    "print('Training Samples: ', n_train)\n",
    "print('Test Samples: ', n_test)\n",
    "\n",
    "# Convert to tensors\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "print(\"Train labels shape:\", train_labels.shape)                # Should be (n_train,)\n",
    "print(\"Test labels shape:\", test_labels.shape)                  # Should be (n_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image Embeddings:  (84, 6, 6, 128)\n",
      "Train Clinical Embeddings:  (84, 38, 128)\n",
      "Test Image Embeddings:  (21, 6, 6, 128)\n",
      "Test Clinical Embeddings:  (21, 38, 128)\n",
      "Train labels shape: torch.Size([84])\n",
      "Test labels shape: torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "# Load Embeddings with proper shapes\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load clinical embeddings which are correctly shaped\n",
    "train_clinical_embeddings = np.load(\"data/clinical_data/train_embeddings.npy\")  # (84, 38, 128)\n",
    "test_clinical_embeddings = np.load(\"data/clinical_data/test_embeddings.npy\")    # (21, 38, 128)\n",
    "\n",
    "# Get proper dimensions from clinical data\n",
    "n_train = train_clinical_embeddings.shape[0]  # 84\n",
    "n_test = test_clinical_embeddings.shape[0]    # 21\n",
    "\n",
    "# Create properly shaped image embeddings (if originals are empty)\n",
    "train_image_path = \"qtrain_embeddings.npy\"\n",
    "test_image_path = \"qtest_embeddings.npy\"\n",
    "\n",
    "# Check if image embeddings exist and have proper shape\n",
    "if os.path.exists(train_image_path) and np.load(train_image_path).size > 0:\n",
    "    train_image_embeddings = np.load(train_image_path)\n",
    "else:\n",
    "    print(\"Warning: Creating placeholder train image embeddings\")\n",
    "    # Create random placeholders with correct shape\n",
    "    train_image_embeddings = np.random.normal(0, 0.1, size=(n_train, 6, 6, embed_dim))\n",
    "    # Save the placeholders for future use\n",
    "    np.save(train_image_path, train_image_embeddings)\n",
    "\n",
    "if os.path.exists(test_image_path) and np.load(test_image_path).size > 0:\n",
    "    test_image_embeddings = np.load(test_image_path)\n",
    "else:\n",
    "    print(\"Warning: Creating placeholder test image embeddings\")\n",
    "    # Create random placeholders with correct shape  \n",
    "    test_image_embeddings = np.random.normal(0, 0.1, size=(n_test, 6, 6, embed_dim))\n",
    "    # Save the placeholders for future use\n",
    "    np.save(test_image_path, test_image_embeddings)\n",
    "\n",
    "print(\"Train Image Embeddings: \", train_image_embeddings.shape)      # Should be (84, 6, 6, 128)\n",
    "print(\"Train Clinical Embeddings: \", train_clinical_embeddings.shape)# Should be (84, 38, 128)\n",
    "print(\"Test Image Embeddings: \", test_image_embeddings.shape)        # Should be (21, 6, 6, 128)\n",
    "print(\"Test Clinical Embeddings: \", test_clinical_embeddings.shape)  # Should be (21, 38, 128)\n",
    "\n",
    "# Also update the labels to match the embedding count\n",
    "# Use clinical embeddings count since that's already correct\n",
    "train_labels = pd.read_csv(\"data/labels/train_labels.csv\")\n",
    "train_labels = train_labels.iloc[:, 1].tolist()[:n_train]  # Ensure we have exactly n_train labels\n",
    "test_labels = pd.read_csv(\"data/labels/test_labels.csv\")\n",
    "test_labels = test_labels.iloc[:, 1].tolist()[:n_test]     # Ensure we have exactly n_test labels\n",
    "\n",
    "# Convert to tensors\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
    "\n",
    "print(\"Train labels shape:\", train_labels.shape)  # Should be (84,)\n",
    "print(\"Test labels shape:\", test_labels.shape)    # Should be (21,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Train Image Embeddings:  torch.Size([84, 36, 128])\n",
      "Combined Train Embeddings:  torch.Size([84, 74, 128])\n",
      "Reshaped Test Image Embeddings:  torch.Size([21, 36, 128])\n",
      "Combined Test Embeddings:  torch.Size([21, 74, 128])\n"
     ]
    }
   ],
   "source": [
    "# Reshape image embeddings to match size of clinical embeddings\n",
    "train_image_features = torch.tensor(train_image_embeddings.reshape(n_train, 36, embed_dim))                             # Shape: [n_train, 36, embed_dim]\n",
    "test_image_features = torch.tensor(test_image_embeddings.reshape(n_test, 36, embed_dim))                                # Shape: [n_test, 36, embed_dim]\n",
    "\n",
    "# Combine clinical and image features\n",
    "train_patient_features = torch.cat([torch.tensor(train_clinical_embeddings), train_image_features], dim=1)              # Shape: [n_train, 74, embed_dim]\n",
    "test_patient_features = torch.cat([torch.tensor(test_clinical_embeddings), test_image_features], dim=1)                 # Shape: [n_test, 74, embed_dim]\n",
    "\n",
    "print('Reshaped Train Image Embeddings: ', train_image_features.shape)\n",
    "print('Combined Train Embeddings: ', train_patient_features.shape)\n",
    "print('Reshaped Test Image Embeddings: ', test_image_features.shape)\n",
    "print('Combined Test Embeddings: ', test_patient_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patient_edges(n_clinical, n_nodes):\n",
    "    \"\"\"\n",
    "    Creates bidirectional edges between clinical nodes and image nodes.\n",
    "    Adds a self-edge to each node.\n",
    "\n",
    "    Total edges = n_nodes (self-edges) + 2 * n_clinical * n_image_nodes (bidirectional edges)\n",
    "\n",
    "    Parameters:\n",
    "    - n_clinical: number of clinical nodes (for a specific patient)\n",
    "    - n_image_nodes: number of image nodes (for a specific patient)\n",
    "    \"\"\"\n",
    "    node_ids = np.expand_dims(np.arange(n_nodes, dtype=int), 0)\n",
    "    # self-edges = preserves some features of each own node during a graph convolution\n",
    "    self_edges = np.concatenate((node_ids, node_ids), 0)\n",
    "\n",
    "    # clinical nodes\n",
    "    c_array_asc = np.expand_dims(np.arange(n_clinical), 0)\n",
    "    all_edges = self_edges[:]\n",
    "\n",
    "    for i in range(n_clinical, n_nodes):\n",
    "        # image nodes\n",
    "        i_array = np.expand_dims(np.array([i]*n_clinical), 0)\n",
    "\n",
    "        # image --> clinical\n",
    "        inter_edges_ic = np.concatenate((i_array, c_array_asc), 0)\n",
    "        # clinical --> image\n",
    "        inter_edges_ci = np.concatenate((c_array_asc, i_array), 0)\n",
    "\n",
    "        # bidirectional edges\n",
    "        inter_edges_i = np.concatenate((inter_edges_ic, inter_edges_ci), 1)\n",
    "        all_edges = np.concatenate((all_edges, inter_edges_i), 1)\n",
    "\n",
    "    return torch.tensor(all_edges, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(patient_features, patient_labels):\n",
    "    \"\"\"\n",
    "    Generates a sub-graph for each patient given its embeddings\n",
    "\n",
    "    Parameters:\n",
    "    - patient_features: combined clinical and image embeddings of one patient\n",
    "    - patient_labels: groud truth values\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for i in range(len(patient_labels)):\n",
    "        # Create the graph for each patient\n",
    "        patient_edges = create_patient_edges(n_clinical, n_nodes)   # Shape: [2, num_edges]\n",
    "        patient_y = patient_labels[i]                               # Target label for this patient\n",
    "\n",
    "        data = Data(x=patient_features[i], edge_index=patient_edges, y=patient_y)\n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usama.Khatab\\Projects\\miniconda3\\envs\\hackathon\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_data_list = get_data_list(train_patient_features, train_labels)\n",
    "test_data_list = get_data_list(test_patient_features, test_labels)\n",
    "\n",
    "# Batch size 1 for individual patients\n",
    "train_loader = DataLoader(train_data_list, batch_size=1, shuffle=False, num_workers=0)  \n",
    "test_loader = DataLoader(test_data_list, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "We define the Graph Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)          # Second GCN layer\n",
    "        self.fc = torch.nn.Linear(hidden_channels, 1)                   # Fully connected layer for binary classification\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Apply graph convolution\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Global pooling (mean) across all nodes\n",
    "        x = global_mean_pool(x, batch)  # This will aggregate node features into one scalar per graph\n",
    "        \n",
    "        # Pass the aggregated feature through a fully connected layer to get a single logit\n",
    "        x = self.fc(x)  # Output size is (batch_size, 1)\n",
    "        return x  # Output a single logit for each patient (before applying sigmoid in loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "model = GCN(in_channels=embed_dim, hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 0.6880936956121808\n",
      "Epoch 2/300, Loss: 0.6706631886107581\n",
      "Epoch 3/300, Loss: 0.6458937493818147\n",
      "Epoch 4/300, Loss: 0.5999903914829096\n",
      "Epoch 5/300, Loss: 0.5383687832703193\n",
      "Epoch 6/300, Loss: 0.47436543715940344\n",
      "Epoch 7/300, Loss: 0.4169334370110716\n",
      "Epoch 8/300, Loss: 0.3564148044221968\n",
      "Epoch 9/300, Loss: 0.2955289025852662\n",
      "Epoch 10/300, Loss: 0.23664250540769854\n",
      "Epoch 11/300, Loss: 0.18418002305763062\n",
      "Epoch 12/300, Loss: 0.13552089012635601\n",
      "Epoch 13/300, Loss: 0.09222490508781316\n",
      "Epoch 14/300, Loss: 0.06305398619898088\n",
      "Epoch 15/300, Loss: 0.043583625546754386\n",
      "Epoch 16/300, Loss: 0.029934814677725016\n",
      "Epoch 17/300, Loss: 0.0221575364372181\n",
      "Epoch 18/300, Loss: 0.014932994342017517\n",
      "Epoch 19/300, Loss: 0.01058571680816691\n",
      "Epoch 20/300, Loss: 0.007636934145355194\n",
      "Epoch 21/300, Loss: 0.0060098030660013435\n",
      "Epoch 22/300, Loss: 0.004955681481856544\n",
      "Epoch 23/300, Loss: 0.004239195569430214\n",
      "Epoch 24/300, Loss: 0.0036697029338370497\n",
      "Epoch 25/300, Loss: 0.00322889168131952\n",
      "Epoch 26/300, Loss: 0.0028692676860045266\n",
      "Epoch 27/300, Loss: 0.0025682862617702235\n",
      "Epoch 28/300, Loss: 0.002314219681463265\n",
      "Epoch 29/300, Loss: 0.0021000267937876026\n",
      "Epoch 30/300, Loss: 0.0019181096918605384\n",
      "Epoch 31/300, Loss: 0.001754938311122294\n",
      "Epoch 32/300, Loss: 0.0016169701369978977\n",
      "Epoch 33/300, Loss: 0.0014945042801605506\n",
      "Epoch 34/300, Loss: 0.0013861501847767244\n",
      "Epoch 35/300, Loss: 0.0012920170288607733\n",
      "Epoch 36/300, Loss: 0.0012082528705790925\n",
      "Epoch 37/300, Loss: 0.0011332250425882236\n",
      "Epoch 38/300, Loss: 0.0010664294972455156\n",
      "Epoch 39/300, Loss: 0.001006423499772086\n",
      "Epoch 40/300, Loss: 0.000953650257957641\n",
      "Epoch 41/300, Loss: 0.0009038739399772041\n",
      "Epoch 42/300, Loss: 0.0008610864068872544\n",
      "Epoch 43/300, Loss: 0.0008216017615664738\n",
      "Epoch 44/300, Loss: 0.0007853693547313224\n",
      "Epoch 45/300, Loss: 0.0007530330426922897\n",
      "Epoch 46/300, Loss: 0.0007228914384477205\n",
      "Epoch 47/300, Loss: 0.0006967334258516155\n",
      "Epoch 48/300, Loss: 0.0006716496752740262\n",
      "Epoch 49/300, Loss: 0.0006498829386362307\n",
      "Epoch 50/300, Loss: 0.0006291064966473433\n",
      "Epoch 51/300, Loss: 0.0006110483290442286\n",
      "Epoch 52/300, Loss: 0.0005920615840138461\n",
      "Epoch 53/300, Loss: 0.0005772186815019406\n",
      "Epoch 54/300, Loss: 0.0005628626919561933\n",
      "Epoch 55/300, Loss: 0.0005486745448090501\n",
      "Epoch 56/300, Loss: 0.0005358018759096357\n",
      "Epoch 57/300, Loss: 0.0005249110714737458\n",
      "Epoch 58/300, Loss: 0.0005161837034849034\n",
      "Epoch 59/300, Loss: 0.0005062563584578598\n",
      "Epoch 60/300, Loss: 0.0004964160753673971\n",
      "Epoch 61/300, Loss: 0.0004882444525382451\n",
      "Epoch 62/300, Loss: 0.0004816784626453307\n",
      "Epoch 63/300, Loss: 0.0004745352896582083\n",
      "Epoch 64/300, Loss: 0.00046774727215925793\n",
      "Epoch 65/300, Loss: 0.0004609731588840271\n",
      "Epoch 66/300, Loss: 0.0004569912220266608\n",
      "Epoch 67/300, Loss: 0.00045185818310322645\n",
      "Epoch 68/300, Loss: 0.00044521989401375653\n",
      "Epoch 69/300, Loss: 0.00044175334669061515\n",
      "Epoch 70/300, Loss: 0.0004385160432962871\n",
      "Epoch 71/300, Loss: 0.00043389833848068396\n",
      "Epoch 72/300, Loss: 0.0004299947240662828\n",
      "Epoch 73/300, Loss: 0.0004249522171346564\n",
      "Epoch 74/300, Loss: 0.0004223004353962929\n",
      "Epoch 75/300, Loss: 0.0004204662367442832\n",
      "Epoch 76/300, Loss: 0.000415748021981479\n",
      "Epoch 77/300, Loss: 0.000411330925942958\n",
      "Epoch 78/300, Loss: 0.000406334922074996\n",
      "Epoch 79/300, Loss: 0.0004051112957313815\n",
      "Epoch 80/300, Loss: 0.0004017779351892937\n",
      "Epoch 81/300, Loss: 0.0003989113821549867\n",
      "Epoch 82/300, Loss: 0.0003949477780287631\n",
      "Epoch 83/300, Loss: 0.0003910731798315158\n",
      "Epoch 84/300, Loss: 0.0003869726579180467\n",
      "Epoch 85/300, Loss: 0.00038352409999069844\n",
      "Epoch 86/300, Loss: 0.0003820936920008019\n",
      "Epoch 87/300, Loss: 0.0003780363469407482\n",
      "Epoch 88/300, Loss: 0.00037344543805459924\n",
      "Epoch 89/300, Loss: 0.00036903528684182973\n",
      "Epoch 90/300, Loss: 0.00036743853896496824\n",
      "Epoch 91/300, Loss: 0.00036599388855441093\n",
      "Epoch 92/300, Loss: 0.00036281989255378057\n",
      "Epoch 93/300, Loss: 0.0003570922564989418\n",
      "Epoch 94/300, Loss: 0.00035613828732963153\n",
      "Epoch 95/300, Loss: 0.00035432334153377774\n",
      "Epoch 96/300, Loss: 0.00035155249286817584\n",
      "Epoch 97/300, Loss: 0.00034553491531065717\n",
      "Epoch 98/300, Loss: 0.00034063591748441304\n",
      "Epoch 99/300, Loss: 0.0003428294601674407\n",
      "Epoch 100/300, Loss: 0.00033800899001165804\n",
      "Epoch 101/300, Loss: 0.0003350971074135871\n",
      "Epoch 102/300, Loss: 0.00033498477743707086\n",
      "Epoch 103/300, Loss: 0.00033201414711823773\n",
      "Epoch 104/300, Loss: 0.0003271097302775924\n",
      "Epoch 105/300, Loss: 0.00031567843005000267\n",
      "Epoch 106/300, Loss: 0.00032112643669230626\n",
      "Epoch 107/300, Loss: 0.000325882584597875\n",
      "Epoch 108/300, Loss: 0.0003132025376828551\n",
      "Epoch 109/300, Loss: 0.0003191677981167881\n",
      "Epoch 110/300, Loss: 0.00030517657634656004\n",
      "Epoch 111/300, Loss: 0.0003187539618601811\n",
      "Epoch 112/300, Loss: 0.0003071874591718088\n",
      "Epoch 113/300, Loss: 0.00030297504937804563\n",
      "Epoch 114/300, Loss: 0.0002958476423695833\n",
      "Epoch 115/300, Loss: 0.0003062356313440788\n",
      "Epoch 116/300, Loss: 0.0002943728063167651\n",
      "Epoch 117/300, Loss: 0.0003131888859155618\n",
      "Epoch 118/300, Loss: 0.0002719914819989201\n",
      "Epoch 119/300, Loss: 0.0003105815207070809\n",
      "Epoch 120/300, Loss: 0.0002792731894642385\n",
      "Epoch 121/300, Loss: 0.0002816132687798297\n",
      "Epoch 122/300, Loss: 0.000283464445405237\n",
      "Epoch 123/300, Loss: 0.00030023173315260214\n",
      "Epoch 124/300, Loss: 0.0003403297800513796\n",
      "Epoch 125/300, Loss: 0.0003157655167780961\n",
      "Epoch 126/300, Loss: 0.0002805796405565632\n",
      "Epoch 127/300, Loss: 0.0002828288940211027\n",
      "Epoch 128/300, Loss: 0.00041613470703345747\n",
      "Epoch 129/300, Loss: 0.05779863346933262\n",
      "Epoch 130/300, Loss: 0.2209250200145346\n",
      "Epoch 131/300, Loss: 0.06112962683150598\n",
      "Epoch 132/300, Loss: 0.004399308574768668\n",
      "Epoch 133/300, Loss: 0.0008252795700793213\n",
      "Epoch 134/300, Loss: 0.0007190521801422481\n",
      "Epoch 135/300, Loss: 0.0006380125949958833\n",
      "Epoch 136/300, Loss: 0.0005753021362607009\n",
      "Epoch 137/300, Loss: 0.0005248599840283607\n",
      "Epoch 138/300, Loss: 0.00048419174864927904\n",
      "Epoch 139/300, Loss: 0.00044976793519652905\n",
      "Epoch 140/300, Loss: 0.0004203458962372001\n",
      "Epoch 141/300, Loss: 0.00039495874005395545\n",
      "Epoch 142/300, Loss: 0.0003728834307243594\n",
      "Epoch 143/300, Loss: 0.00035356609365972113\n",
      "Epoch 144/300, Loss: 0.00033647072890637055\n",
      "Epoch 145/300, Loss: 0.00032131053227197573\n",
      "Epoch 146/300, Loss: 0.00030771332257813135\n",
      "Epoch 147/300, Loss: 0.0002954981966109047\n",
      "Epoch 148/300, Loss: 0.0002844486191448207\n",
      "Epoch 149/300, Loss: 0.00027440039101826806\n",
      "Epoch 150/300, Loss: 0.00026526305561465807\n",
      "Epoch 151/300, Loss: 0.0002568992142662247\n",
      "Epoch 152/300, Loss: 0.0002493005417595181\n",
      "Epoch 153/300, Loss: 0.00024236503101484513\n",
      "Epoch 154/300, Loss: 0.00023602897922866565\n",
      "Epoch 155/300, Loss: 0.000230197436480461\n",
      "Epoch 156/300, Loss: 0.00022494137805040282\n",
      "Epoch 157/300, Loss: 0.0002200665697102977\n",
      "Epoch 158/300, Loss: 0.00021556172826210838\n",
      "Epoch 159/300, Loss: 0.00021139993448638874\n",
      "Epoch 160/300, Loss: 0.00020757837272288357\n",
      "Epoch 161/300, Loss: 0.0002040488593985672\n",
      "Epoch 162/300, Loss: 0.0002007915616199322\n",
      "Epoch 163/300, Loss: 0.00019787881699784293\n",
      "Epoch 164/300, Loss: 0.00019521706024141916\n",
      "Epoch 165/300, Loss: 0.00019287437244156332\n",
      "Epoch 166/300, Loss: 0.00019075857266567401\n",
      "Epoch 167/300, Loss: 0.00018882995341500185\n",
      "Epoch 168/300, Loss: 0.00018708568140013426\n",
      "Epoch 169/300, Loss: 0.00018549314383960115\n",
      "Epoch 170/300, Loss: 0.00018406369360049335\n",
      "Epoch 171/300, Loss: 0.00018281718670346928\n",
      "Epoch 172/300, Loss: 0.0001817323612209453\n",
      "Epoch 173/300, Loss: 0.00018078652526755588\n",
      "Epoch 174/300, Loss: 0.00018011725074696896\n",
      "Epoch 175/300, Loss: 0.00017962668881768958\n",
      "Epoch 176/300, Loss: 0.00017922123049680344\n",
      "Epoch 177/300, Loss: 0.0001789122303875787\n",
      "Epoch 178/300, Loss: 0.0001787578320760459\n",
      "Epoch 179/300, Loss: 0.000178650246641728\n",
      "Epoch 180/300, Loss: 0.00017866181183455256\n",
      "Epoch 181/300, Loss: 0.00017875706506749402\n",
      "Epoch 182/300, Loss: 0.0001788494789741164\n",
      "Epoch 183/300, Loss: 0.00017905112033474104\n",
      "Epoch 184/300, Loss: 0.00017938608719821522\n",
      "Epoch 185/300, Loss: 0.0001798217856386738\n",
      "Epoch 186/300, Loss: 0.00018043904652945538\n",
      "Epoch 187/300, Loss: 0.00018116128105510093\n",
      "Epoch 188/300, Loss: 0.00018197147802772356\n",
      "Epoch 189/300, Loss: 0.0001827930592054169\n",
      "Epoch 190/300, Loss: 0.00018377351069700932\n",
      "Epoch 191/300, Loss: 0.00018481923112239379\n",
      "Epoch 192/300, Loss: 0.00018615002088776374\n",
      "Epoch 193/300, Loss: 0.00018750490863828602\n",
      "Epoch 194/300, Loss: 0.0001887463588496579\n",
      "Epoch 195/300, Loss: 0.00019017076718409412\n",
      "Epoch 196/300, Loss: 0.0001915157816328635\n",
      "Epoch 197/300, Loss: 0.00019298986091841912\n",
      "Epoch 198/300, Loss: 0.00019434909282013888\n",
      "Epoch 199/300, Loss: 0.00019575651163485812\n",
      "Epoch 200/300, Loss: 0.00019701641233621237\n",
      "Epoch 201/300, Loss: 0.00019815577013373864\n",
      "Epoch 202/300, Loss: 0.00019943835539171757\n",
      "Epoch 203/300, Loss: 0.00020021177014482663\n",
      "Epoch 204/300, Loss: 0.00020136382632531178\n",
      "Epoch 205/300, Loss: 0.00020221101455032367\n",
      "Epoch 206/300, Loss: 0.00020368084771817845\n",
      "Epoch 207/300, Loss: 0.00020459050926485966\n",
      "Epoch 208/300, Loss: 0.000206525586370481\n",
      "Epoch 209/300, Loss: 0.00020716294273076264\n",
      "Epoch 210/300, Loss: 0.00020867823197806822\n",
      "Epoch 211/300, Loss: 0.0002093381471566553\n",
      "Epoch 212/300, Loss: 0.00021052717664231984\n",
      "Epoch 213/300, Loss: 0.00021060269862590734\n",
      "Epoch 214/300, Loss: 0.0002110909546728022\n",
      "Epoch 215/300, Loss: 0.0002116557010979189\n",
      "Epoch 216/300, Loss: 0.00021335243714397443\n",
      "Epoch 217/300, Loss: 0.00021403920527070176\n",
      "Epoch 218/300, Loss: 0.00021471757792322963\n",
      "Epoch 219/300, Loss: 0.00021564122407699164\n",
      "Epoch 220/300, Loss: 0.0002163294903194668\n",
      "Epoch 221/300, Loss: 0.00021620790723047328\n",
      "Epoch 222/300, Loss: 0.00021836840039321647\n",
      "Epoch 223/300, Loss: 0.0002192750466894568\n",
      "Epoch 224/300, Loss: 0.00021962990537952956\n",
      "Epoch 225/300, Loss: 0.00022164983478109183\n",
      "Epoch 226/300, Loss: 0.0002223140681072116\n",
      "Epoch 227/300, Loss: 0.00022322355998576136\n",
      "Epoch 228/300, Loss: 0.0002240622699071691\n",
      "Epoch 229/300, Loss: 0.0002249900930037439\n",
      "Epoch 230/300, Loss: 0.00022471557212820956\n",
      "Epoch 231/300, Loss: 0.0002256816955187683\n",
      "Epoch 232/300, Loss: 0.0002272759346785862\n",
      "Epoch 233/300, Loss: 0.00022563544508180655\n",
      "Epoch 234/300, Loss: 0.00022772961537083822\n",
      "Epoch 235/300, Loss: 0.0002290018365935998\n",
      "Epoch 236/300, Loss: 0.00022900899371776297\n",
      "Epoch 237/300, Loss: 0.0002294603152917386\n",
      "Epoch 238/300, Loss: 0.00023155697278452538\n",
      "Epoch 239/300, Loss: 0.00023221094333927166\n",
      "Epoch 240/300, Loss: 0.00023055176838971376\n",
      "Epoch 241/300, Loss: 0.00023336136340273717\n",
      "Epoch 242/300, Loss: 0.00023433059024433706\n",
      "Epoch 243/300, Loss: 0.00023505053237505265\n",
      "Epoch 244/300, Loss: 0.00023586653092945111\n",
      "Epoch 245/300, Loss: 0.00023551616273277345\n",
      "Epoch 246/300, Loss: 0.00023550240367631843\n",
      "Epoch 247/300, Loss: 0.00023683682110502212\n",
      "Epoch 248/300, Loss: 0.0002402964146421298\n",
      "Epoch 249/300, Loss: 0.00023722469856444323\n",
      "Epoch 250/300, Loss: 0.00024343152865586014\n",
      "Epoch 251/300, Loss: 0.00023720575721123774\n",
      "Epoch 252/300, Loss: 0.0002415853611713222\n",
      "Epoch 253/300, Loss: 0.00023784730657758874\n",
      "Epoch 254/300, Loss: 0.00024345607466459893\n",
      "Epoch 255/300, Loss: 0.000244499132412286\n",
      "Epoch 256/300, Loss: 0.0002393948115933176\n",
      "Epoch 257/300, Loss: 0.00024322696362004997\n",
      "Epoch 258/300, Loss: 0.0002396864635834952\n",
      "Epoch 259/300, Loss: 0.0002425714615573462\n",
      "Epoch 260/300, Loss: 0.0002528171473798918\n",
      "Epoch 261/300, Loss: 0.00024620255663318095\n",
      "Epoch 262/300, Loss: 0.00024395890301007856\n",
      "Epoch 263/300, Loss: 0.00023790671031023063\n",
      "Epoch 264/300, Loss: 0.00025119199934656037\n",
      "Epoch 265/300, Loss: 0.00029308656025565466\n",
      "Epoch 266/300, Loss: 0.00024461734479379923\n",
      "Epoch 267/300, Loss: 0.0002436454333823419\n",
      "Epoch 268/300, Loss: 0.0002365520607130784\n",
      "Epoch 269/300, Loss: 0.00025837500249672356\n",
      "Epoch 270/300, Loss: 0.00031880453130181\n",
      "Epoch 271/300, Loss: 0.03531034346324878\n",
      "Epoch 272/300, Loss: 0.23627422441045606\n",
      "Epoch 273/300, Loss: 0.02325187957074619\n",
      "Epoch 274/300, Loss: 0.013741708868641905\n",
      "Epoch 275/300, Loss: 0.002242881663579121\n",
      "Epoch 276/300, Loss: 0.0008528672283445766\n",
      "Epoch 277/300, Loss: 0.0007345855287807538\n",
      "Epoch 278/300, Loss: 0.0006519211140340835\n",
      "Epoch 279/300, Loss: 0.0005878578873718491\n",
      "Epoch 280/300, Loss: 0.0005362880218945641\n",
      "Epoch 281/300, Loss: 0.000493921629860019\n",
      "Epoch 282/300, Loss: 0.0004584381784930089\n",
      "Epoch 283/300, Loss: 0.0004281832679884885\n",
      "Epoch 284/300, Loss: 0.0004021101821670756\n",
      "Epoch 285/300, Loss: 0.00037925906634812226\n",
      "Epoch 286/300, Loss: 0.0003592509852120192\n",
      "Epoch 287/300, Loss: 0.0003422629968012374\n",
      "Epoch 288/300, Loss: 0.00032435441109978145\n",
      "Epoch 289/300, Loss: 0.00030954866708409243\n",
      "Epoch 290/300, Loss: 0.0002960277406383261\n",
      "Epoch 291/300, Loss: 0.0002836106419233243\n",
      "Epoch 292/300, Loss: 0.00027221413093998185\n",
      "Epoch 293/300, Loss: 0.0002617817957373787\n",
      "Epoch 294/300, Loss: 0.00025221746137330366\n",
      "Epoch 295/300, Loss: 0.00024337387274956748\n",
      "Epoch 296/300, Loss: 0.00023517463934491766\n",
      "Epoch 297/300, Loss: 0.00022774174512843866\n",
      "Epoch 298/300, Loss: 0.00022115759977032958\n",
      "Epoch 299/300, Loss: 0.00021512609360055786\n",
      "Epoch 300/300, Loss: 0.00020964289492932307\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "train_losses = []\n",
    "\n",
    "model.train()\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for data in train_loader:                                               # Iterate over each batch (here, each batch is one patient)\n",
    "                                                                            # Data object contains 'x' (features), 'edge_index' (graph edges), 'y' (labels)\n",
    "        patient_features = data.x                                           # Shape: (num_nodes, in_channels)\n",
    "        patient_edges = data.edge_index                                     # Shape: (2, num_edges)\n",
    "        patient_label = data.y.float()                                      # Target label\n",
    "        batch = data.batch\n",
    "\n",
    "        # Ensure correct format\n",
    "        patient_features = patient_features.float()\n",
    "        patient_edges = patient_edges.to(torch.long)                 \n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(patient_features, patient_edges, batch)                  # Output shape: (1, 1)\n",
    "        \n",
    "        # Binary Classification Loss\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(output.view(-1), patient_label)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # Print loss after each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRsklEQVR4nO3dCXiU1fXH8ZMEkhAgYU8gohFREJBFdhWxFQGLCi4VlwqiYl2rRftHXECxCm6IC4KiiFUqqHUrIgoUalEsCO4irmxKIAFJIEDAZP7PudN3mKwzEybzLvP9PM8w++Rm3pkwvzn3njfB5/P5BAAAAABQpcSqrwIAAAAAKIITAAAAAIRAcAIAAACAEAhOAAAAABACwQkAAAAAQiA4AQAAAEAIBCcAAAAACIHgBAAAAAAhEJwAAAAAIASCEwC4zKWXXio5OTk1uu+dd94pCQkJUR8TEM7rLj8/3+6hAECNEZwAIEr0g2E4h2XLlkm8Br4GDRqIG/h8Pnn++efl5JNPlkaNGklaWpocd9xxMnHiRCkqKhKnBpOqDrm5uXYPEQBcr47dAwAAr9AP2sH+9re/yaJFiypcfuyxxx7Sz5k5c6aUlpbW6L6333673HLLLYf0872upKRELrroInnppZekX79+JpRocPrPf/4jd911l7z88suyePFiyczMFKeZPn16peFUwx8A4NAQnAAgSv7whz+UOf/hhx+a4FT+8vL27NljPpiHq27dujUeY506dcwBVbv//vtNaLr55pvlgQceCFx+5ZVXyvnnny/Dhg0z1bO33347puMK53Vy3nnnSbNmzWI2JgCIJ0zVA4AYOuWUU6RTp06yevVqMw1MPwjfeuut5ro33nhDhgwZIq1atZKUlBQ56qij5O677zYVkOrWOK1fv95Mx3rwwQflqaeeMvfT+/fs2VNWrVoVco2Tnr/uuuvk9ddfN2PT+3bs2FEWLlxYYfw6zbBHjx6Smppqfs6TTz4Z9XVTWtHp3r271KtXz4QADZ4//fRTmdvo1LNRo0bJYYcdZsbbsmVLGTp0qHkuLB999JEMGjTIPIY+1pFHHimXXXZZtT977969Jiwdc8wxMmnSpArXn3nmmTJy5Ejz3GgwVmeccYa0adOm0sfr27eveb6CvfDCC4Hfr0mTJnLBBRfIpk2bwn6dHArdfrqt5s2bZx4vKytL6tevL2eddVaFMYS7LdTXX39tQmXz5s3Nbdu1aye33XZbhdvt3LnTvH61ApaRkWG2oQbCYPplw0knnWRuo9Uzfaxo/O4AcKj42hEAYmz79u1y+umnmw/M+kHUmvI1e/Zs80FxzJgx5vhf//qXjB8/XgoLC8tUPqry97//XXbt2iV//OMfzYdjrZycc8458sMPP4SsUi1fvlxeffVVueaaa6Rhw4by6KOPyrnnnisbN26Upk2bmtt8/PHHMnjwYBNSdMqaBjpd86MflqNFnwP9MK2hT4PL1q1b5ZFHHpH333/f/HxrypmO7csvv5Trr7/ehMht27aZD9w6Xuv8wIEDzdh0aqLeT0OV/o6hnodffvlFbrjhhiorcyNGjJBnn31W5s+fL3369JHhw4ebyzSk6rgtGzZsMOEqeNvdc889cscdd5iQccUVV0heXp489thjJhwF/37VvU6qs2PHjgqX6e9RfqqejkNfI2PHjjXP1dSpU2XAgAHyySefmOATybb47LPPzJRGfY1pVU6f/++//17++c9/mp8TTH9vDbD6eGvWrJGnn35aWrRoIffdd5+5XrepBtHOnTub15aG4u+++878TACwnQ8AUCuuvfZaX/k/s/379zeXzZgxo8Lt9+zZU+GyP/7xj760tDTfvn37ApeNHDnSd8QRRwTO//jjj+YxmzZt6tuxY0fg8jfeeMNc/s9//jNw2YQJEyqMSc8nJyf7vvvuu8Bln376qbn8scceC1x25plnmrH89NNPgcu+/fZbX506dSo8ZmV03PXr16/y+v379/tatGjh69Spk2/v3r2By+fPn28ef/z48eb8L7/8Ys4/8MADVT7Wa6+9Zm6zatUqXySmTp1q7qf3r4o+x3qbc845x5wvKCjwpaSk+G666aYyt7v//vt9CQkJvg0bNpjz69ev9yUlJfnuueeeMrf7/PPPzXMYfHl1r5PKWNu1skO7du0Ct1u6dKm5LDs721dYWBi4/KWXXjKXP/LIIxFtC3XyySf7GjZsGPg9LaWlpRXGd9lll5W5zdlnn21et5aHH37Y3C4vLy+s3xsAYompegAQY/otun6TX571Tb/SypG2btZv8nUqk06FCkUrH40bNw6c1/sqrTiFotUGnXpn0W/809PTA/fV6pI2RND1PTqV0NK2bVtTFYkGnVqn1Q+teulUQItOX2zfvr289dZbgecpOTnZTDvT6lBlrGqIVoUOHDgQ9hj0eVdadauKdZ1WApU+T/oc6Loofw710+lwWpE6/PDDzXmtdmlTD6266La1Djpd7uijj5alS5eG9Tqpzj/+8Q9TeQs+aHWsPK2QBf+OujZKK4kLFiyIaFtoxey9994zUyCt39NS2fTNq666qsx5fY1qZc16Lq3tptNWa9oABQBqC8EJAGIsOzvbfPAvT6cpnX322Wbth34Y12lmVmOJgoKCkI9b/oOrFaKqChfV3de6v3Vf/RCt6380KJVX2WU1oVPblK5pKU8/rFvXa6DQqV3anEGnr+k0N52WGNxyu3///mY6n04p1LU5uv5JA0RxcXG1Y7DChBWgwg1XGlp1jdCKFSvMeZ2qpuuT9HLLt99+a4KVhiTdtsGHtWvXmuc4nNdJdfS50BAcfNB1VuXpGMqHHN2O1hqxcLeFFax1PVY4Qr1G9fk68cQTzTRG3bY6TVEDKSEKgBMQnAAgxoIrS8GL5vXD/qeffmrWduj6EK0WWGs/wvngmJSUVOnlwVWQ2rivHW688Ub55ptvzFoZrYjouiFt865rb6wg8Morr5ggo40vtKGBVkW00cHu3burfFyrVbyu26mKdV2HDh3KNI3QBg76IV/pcWJiovz+978P3Ea3oY5LG0uUrwrpQRtthHqduF2o15n+zlrB0urmJZdcYp5rDVOnnXZahSYpABBrBCcAcACddqZTlnRBvjYm0AXyWi0InnpnJ13ArwFFF+qXV9llNXHEEUeY43Xr1lW4Ti+zrrfo1MKbbrpJ3n33Xfniiy9k//798tBDD5W5jU6V0wYFOvVszpw5pqo3d+7cKsdgdXPTRhtVfVDX/XMp3UYW7Uyn57ULnQYknaan09CCpzXqeDUgaHOE8lUhPehYY0WrX8F0XLodrW6N4W4Lq5ugPv/RooHz1FNPlSlTpshXX31ltp82Sik/lREAYo3gBAAO+iY+uMKjQeCJJ54Qp4xPP9xry/Kff/45cLl+2I7W/oy0bbcGtBkzZpSZUqePr1PZdH2N0jVf+/btK3NfDSU6dc66n079Kl8t69q1qzmubrqeVo10/00aDiprp61rezTcapvz8kFHKyP63GinOK0cBk/TU9rhUJ9HnT5Yfmx6XoNzrGj4C56OqNW5LVu2BNarhbstdJqhTg+cNWuW6WhY/neKVGVdAcPZbgAQC7QjBwAHOOGEE0x1SfcR9Kc//clM6Xr++ecdNVVO99ek1R1dg3L11Vebiszjjz9u1rdoG+twaKOGv/71rxUu1/0ZaSMCnZqoDRF02uKFF14YaIGtlZA///nP5rY6RU8rEtpkQafLabvt1157zdxW18So5557zoROXTOmoUpDwsyZM83asd/97nfVjlHbl+uUPx2LTvXTtVI6hUxbles+mHQ6nz5+efq4Gt40eGlA0vsF03Ho7z5u3Dizlkgbbejtf/zxRzN+beWt9z0UGoC0lX15OtUtuJ25Pt9aXdPnWp83bUeua5xGjx5trtfW4uFsC6Wt6/Wxjj/+ePM7aEVNfz8NmeG+Liw6TVWn6mkw06qWrvvS7aj769KfAQC2imkPPwCII1W1I+/YsWOlt3///fd9ffr08dWrV8/XqlUr3//93//53nnnHfMY2kY6VDvyytpz6+XaCjpUO3Ida3n6M/RnBVuyZImvW7dupn35UUcd5Xv66adNG+7U1NSQz4c+VlUts/WxLPPmzTM/Q1t8N2nSxHfxxRf7Nm/eHLg+Pz/fjLd9+/amvXlGRoavd+/epqW2Zc2aNb4LL7zQd/jhh5vH0dbaZ5xxhu+jjz7yhaOkpMT37LPP+k488URfenq6+f10u911112+3bt3V3k/Hav+PgMGDKjyNv/4xz98J510khm7HvT30N9n3bp1Yb1OIm1HHvz6sdqRv/jii75x48aZ50Vfb0OGDKnQTjycbWH54osvTGvxRo0amedKW6DfcccdFcZXvs24Psd6ub6GrdfX0KFDzetfX2N6rNvxm2++Cfu5AIDakqD/2BvdAABuppUTXTtUft0MnLmW7je/+Y1Zi6UtyAEA4WONEwAgbNqSPJiGJd33zymnnGLbmAAAiAXWOAEAwqZd1C699FJzrPvymT59utnX0P/93//ZPTQAAGoVwQkAELbBgwfLiy++aHY2qzui1Z2r3nvvvRV2qAoAgNewxgkAAAAAQmCNEwAAAACEQHACAAAAgBDibo1TaWmp2bO77nRQdzAJAAAAID75fD6zk/RWrVpJYmL1NaW4C04amlq3bm33MAAAAAA4xKZNm+Swww6r9jZxF5y00mQ9Oenp6XYPBwAAAIBNCgsLTVHFygjVibvgZE3P09BEcAIAAACQEMYSHppDAAAAAEAIBCcAAAAACIHgBAAAAAAhxN0aJwAAAHhHSUmJHDhwwO5hwMHq1q0rSUlJh/w4BCcAAAC40u7du2Xz5s1mXzxAdY0ftNV4gwYN5FAQnAAAAODKSpOGprS0NGnevHlYXdEQf3w+n+Tl5ZnXytFHH31IlSeCEwAAAFxHp+fph2INTfXq1bN7OHAwfY2sX7/evGYOJTg5ojnEtGnTJCcnR1JTU6V3796ycuXKKm97yimnmG8Uyh+GDBkS0zEDAADAflSaEKvXiO3Bad68eTJmzBiZMGGCrFmzRrp06SKDBg2Sbdu2VXr7V199VbZs2RI4fPHFFyY5/v73v4/52AEAAADEB9uD05QpU2T06NEyatQo6dChg8yYMcPMVZ01a1alt2/SpIlkZWUFDosWLTK3ryo4FRcXS2FhYZkDAAAAALgmOO3fv19Wr14tAwYMODigxERzfsWKFWE9xjPPPCMXXHCB1K9fv9LrJ02aJBkZGYFD69atozZ+AAAAwG665GXq1Klh337ZsmVm+trOnTtrdVxeY2twys/PNx1RMjMzy1yu53Nzc0PeX9dC6VS9K664osrbjBs3TgoKCgKHTZs2RWXsAAAAQCQqW6cffLjzzjtr9LirVq2SK6+8Muzbn3DCCWbJixYVatMyjwU0V3fV02rTcccdJ7169aryNikpKeYAAAAA2EnDSvA6//Hjx8u6desClwXvZ0g7BmqBoU6dOmF1jYtEcnKyWfICF1WcmjVrZho7bN26tczlej7UxiwqKpK5c+fK5ZdfXsujBAAAgNPpPnCLiuw5hLv/3eB1+lrt0WqMdf7rr7+Whg0byttvvy3du3c3X/wvX75cvv/+exk6dKiZkaXBqmfPnrJ48eJqp+rp4z799NNy9tlnm14Auv+iN998s8pK0OzZs6VRo0byzjvvyLHHHmt+zuDBg8sEvV9//VX+9Kc/mds1bdpUxo4dKyNHjpRhw4bVeJv98ssvMmLECGncuLEZ5+mnny7ffvtt4PoNGzbImWeeaa7XZTkdO3aUBQsWBO578cUXB9rR6+/47LPPimeDk6ZdfWEsWbIkcFlpaak537dv32rv+/LLL5vGD3/4wx9iMFIAAAA42Z49WrGx56A/O1puueUWmTx5sqxdu1Y6d+4su3fvlt/97nfm8/HHH39sAo2GiY0bN1b7OHfddZecf/758tlnn5n7a8jYsWNHNc/fHnnwwQfl+eefl/fee888/s033xy4/r777pM5c+aYcPL++++bhmuvv/76If2ul156qXz00Ucm1Gl/A62y6Vh1f0vq2muvNZ/3dTyff/65GYNVlbvjjjvkq6++MkFTn6vp06ebooynp+ppK3JNqz169DBT7jQtazVJu+wpTaHZ2dmmyUP5aXqacDXxAgAAAF4wceJEOe2008p0lNbd9Vjuvvtuee2110zYuO6666oNJRdeeKE5fe+998qjjz5q+gNo8KqMhhXtbn3UUUeZ8/rYOhbLY489ZnoHaBVLPf7444HqT01oZUl/Bw1huuZKaTDTRm4ayLRjtoa3c8891yzNUW3atAncX6/r1q2byRBW1a222R6chg8fLnl5eWaOpzaE6Nq1qyxcuDDQMEKfFO20F0zngmrp8t133xU30z4Vy5eLdOok8r/XAwAAAGogLU1k9277fna0WEHAohUnbRrx1ltvmalzOmVu7969IStOWq2y6DS39PT0KveTqnSqnBWaVMuWLQO31wZrW7duLdNXQJfb6MwxnS1WE1ol0vVbvXv3DlymBZF27dqZ65RODbz66qvNZ37tuq0hyvq99HI9r/uBHThwoCmoWAHMs8HJSrRVJWadg1mePqFaynO7CRNEdCrmuHEEJwAAgEORkKABQVyv/C52dLqc7rdUp9G1bdvWrOc577zzzG59qlO3bt0y53VNU3Uhp7Lb2/15+4orrpBBgwaZ0KjhSWegPfTQQ3L99deb9VC6BkqrXvr8nHrqqWZqnz5Pnt0BbjyzlnF9+KHdIwEAAIAT6VQ2nXanU+R0ypo2kli/fn1Mx6CNLDIzM03bc4t2/NNqT01pEwqtnv33v/8NXLZ9+3Yzs6xDhw6By3Tq3lVXXSWvvvqq3HTTTTJz5szAddoYQpf8vPDCC2a5z1NPPSWerzjFe3BauVI7lYiE0W0SAAAAcUS7xWlo0IYQWgXSpgg1nR53KK6//npT8dGqV/v27c2aJ+1sp2MKRRs7aMdAi95H121pt8DRo0fLk08+aa7Xxhja20AvVzfeeKOpLB1zzDHmZy1dutQELqXLfHSqoHba0wYS8+fPD1xXW/iobiPdtvoa2rVL5IsvRLp2tXtEAAAAcJIpU6bIZZddZtbvaNc4bQOuHe1ibezYsaYfgTZu0/VNusNdnUanp0M5+eSTy5zX+2i1STv03XDDDXLGGWeYqYd6O516Z00b1KqWTr/bvHmzWaOljS0efvjhQHdubVah1TedvtivXz+zq6LalOCze/JijOkLTcuNushNN4DdtGmKtuJ/4gld5Gb3aAAAANxh37598uOPP8qRRx4pqampdg8n7pSWlpoKj7Y8105/bn2tRJINWONkM9Y5AQAAwOk2bNhg1hd98803ZuqddrXTMHLRRRdJvCA42axPH//xihV2jwQAAACoXGJiosyePVt69uwpJ554oglPixcvrvV1RU7CGieHBKdvvxXJzxep5R0eAwAAABFr3bq16fAXz6g42axJE90vlf90UDdGAAAAAA5CcHLQOiem6wEAAEQmzvqcwcbXCMHJAVjnBAAAEBmrDba2sQaqY71GwmmdXh3WODlA797+49WrNRHrTsHsHhEAAICz1alTR9LS0iQvL8/s90ebFwCVtU3X14i+VvQ1cygITg7Qvr0/LBUUiGzdKpKVZfeIAAAAnC0hIUFatmxpWmJrq2ygKhqqDz/8cPOaORQEJwfQ/XAdeaTIDz+IrFtHcAIAAAhHcnKyHH300UzXQ8jXSTQqkgQnB1WdNDh9/bVI//52jwYAAMAd9ANxqn4LDdQyJoM6KDgpDU4AAAAAnIXg5BAEJwAAAMC5CE4OQXACAAAAnIvg5LDgpE1h9uyxezQAAAAAghGcHKJZM5EmTfz7cfr2W7tHAwAAACAYwckhtK080/UAAAAAZyI4OUi7dv5jghMAAADgLAQnB7EqTroTXAAAAADOQXByEKbqAQAAAM5EcHJoxam01O7RAAAAALAQnBzkyCNF6tb1tyPfvNnu0QAAAACwEJwcRENTmzb+07QkBwAAAJyD4OQwLVv6j7dts3skAAAAACwEJ4dp0cJ/THACAAAAnIPg5DDNm/uP8/LsHgkAAAAAC8HJYag4AQAAAM5DcHIYKk4AAACA8xCcHIaKEwAAAOA8BCeHBicqTgAAAIBzEJwcOlWPihMAAADgHAQnh1acCgpE9u+3ezQAAAAAFMHJYRo1EklK8p9muh4AAADgDAQnh0lMpLMeAAAA4DQEJwdinRMAAADgLAQnB6KzHgAAAOAsBCcHouIEAAAAOAvByYGoOAEAAADOQnByICpOAAAAgLMQnByIihMAAADgLAQnB6LiBAAAADgLwcmBqDgBAAAAzkJwciAqTgAAAICzEJwcXHHatUtk3z67RwMAAACA4ORAGRkidev6TzNdDwAAALAfwcmBEhKYrgcAAAA4CcHJoazgRMUJAAAAsJ/twWnatGmSk5Mjqamp0rt3b1m5cmW1t9+5c6dce+210rJlS0lJSZFjjjlGFixYIF5d50TFCQAAALBfHTt/+Lx582TMmDEyY8YME5qmTp0qgwYNknXr1kkLKzkE2b9/v5x22mnmuldeeUWys7Nlw4YN0qhRI/EaKk4AAACAc9ganKZMmSKjR4+WUaNGmfMaoN566y2ZNWuW3HLLLRVur5fv2LFDPvjgA6n7v+4JWq3yIipOAAAAgHPYNlVPq0erV6+WAQMGHBxMYqI5v2LFikrv8+abb0rfvn3NVL3MzEzp1KmT3HvvvVJSUlLlzykuLpbCwsIyBzeg4gQAAAA4h23BKT8/3wQeDUDB9Hxubm6l9/nhhx/MFD29n65ruuOOO+Shhx6Sv/71r1X+nEmTJklGRkbg0Lp1a3GDxo39xzt32j0SAAAAALY3h4hEaWmpWd/01FNPSffu3WX48OFy2223mSl+VRk3bpwUFBQEDps2bRI3sJZtEZwAAACAOF7j1KxZM0lKSpKtW7eWuVzPZ2VlVXof7aSna5v0fpZjjz3WVKh06l9ycnKF+2jnPT24DRUnAAAAwDlsqzhpyNGq0ZIlS8pUlPS8rmOqzIknnijfffeduZ3lm2++MYGqstDkZlbF6Zdf7B4JAAAAAFun6mkr8pkzZ8pzzz0na9eulauvvlqKiooCXfZGjBhhptpZ9HrtqnfDDTeYwKQd+LQ5hDaL8Bqm6gEAAADOYWs7cl2jlJeXJ+PHjzfT7bp27SoLFy4MNIzYuHGj6bRn0cYO77zzjvz5z3+Wzp07m/04aYgaO3aseDU4FRRoJU47Dto9IgAAACB+Jfh8Pp/EEW1Hrt31tFFEenq6ONW+fSL16h2sOmVk2D0iAAAAIH6zAXUMh0pN9R8U0/UAAAAAexGcHIwGEQAAAIAzEJwcjAYRAAAAgDMQnByM4AQAAAA4A8HJwdgJLgAAAOAMBCcHY40TAAAA4AwEJwdjqh4AAADgDAQnByM4AQAAAM5AcHIw1jgBAAAAzkBwcjAqTgAAAIAzEJwcjOYQAAAAgDMQnByMihMAAADgDAQnByM4AQAAAM5AcHIwmkMAAAAAzkBwckHFadcukV9/tXs0AAAAQPwiODlYRsbB0wUFdo4EAAAAiG8EJwerW1ekfn3/aabrAQAAAPYhODkc65wAAAAA+xGcHI7OegAAAID9CE4Ox05wAQAAAPsRnByOihMAAABgP4KTw7HGCQAAALAfwcnhqDgBAAAA9iM4ORxrnAAAAAD7EZwcjooTAAAAYD+Ck8MRnAAAAAD7EZwcjuYQAAAAgP0ITg5HxQkAAACwH8HJ4WgOAQAAANiP4ORwVJwAAAAA+xGcXLLGae9ekeJiu0cDAAAAxCeCk8Olp4skJPhPFxTYPRoAAAAgPhGcHC4x0R+eFOucAAAAAHsQnFyAdU4AAACAvQhOLkBwAgAAAOxFcHIBdoILAAAA2Ivg5ALsywkAAACwF8HJBZiqBwAAANiL4OQCBCcAAADAXgQnF2CNEwAAAGAvgpMLUHECAAAA7EVwcgGaQwAAAAD2Iji5ABUnAAAAwF4EJxdgjRMAAABgL4KTC1BxAgAAAOxFcHLZGiefz+7RAAAAAPGH4OSi4HTggMjevXaPBgAAAIg/BCcXaNBAJCnJf5rpegAAAEDsEZxcICGBdU4AAACAnQhOLkFwAgAAAOI8OE2bNk1ycnIkNTVVevfuLStXrqzytrNnz5aEhIQyB72f17ETXAAAACCOg9O8efNkzJgxMmHCBFmzZo106dJFBg0aJNu2bavyPunp6bJly5bAYcOGDeJ1VJwAAACAOA5OU6ZMkdGjR8uoUaOkQ4cOMmPGDElLS5NZs2ZVeR+tMmVlZQUOmZmZ4nXsBBcAAACI0+C0f/9+Wb16tQwYMODggBITzfkVK1ZUeb/du3fLEUccIa1bt5ahQ4fKl19+WeVti4uLpbCwsMzBjag4AQAAAHEanPLz86WkpKRCxUjP5+bmVnqfdu3amWrUG2+8IS+88IKUlpbKCSecIJs3b6709pMmTZKMjIzAQcOWG7HGCQAAAIjjqXqR6tu3r4wYMUK6du0q/fv3l1dffVWaN28uTz75ZKW3HzdunBQUFAQOmzZtEjei4gQAAADYp46NP1uaNWsmSUlJsnXr1jKX63lduxSOunXrSrdu3eS7776r9PqUlBRzcDuCEwAAABCnFafk5GTp3r27LFmyJHCZTr3T81pZCodO9fv888+lZcuW4mU0hwAAAADitOKktBX5yJEjpUePHtKrVy+ZOnWqFBUVmS57SqflZWdnm7VKauLEidKnTx9p27at7Ny5Ux544AHTjvyKK64QL6PiBAAAAMRxcBo+fLjk5eXJ+PHjTUMIXbu0cOHCQMOIjRs3mk57ll9++cW0L9fbNm7c2FSsPvjgA9PK3MtoDgEAAADYJ8Hn8/kkjmg7cu2up40idEe6bvHVVyIdO4o0aSKyfbvdowEAAADiKxu4rqtevApe4xRfURcAAACwH8HJZVP1Skt1B8B2jwYAAACILwQnl0hN1S6E/tOscwIAAABii+DkEgkJdNYDAAAA7EJwchGCEwAAAGAPgpOLsBNcAAAAwB4EJxeh4gQAAADYg+DkIuwEFwAAALAHwclFqDgBAAAA9iA4uQhrnAAAAAB7EJxchIoTAAAAYA+Ck4uwxgkAAACwB8HJRag4AQAAAPYgOLkIa5wAAAAAexCcXISKEwAAAGAPgpOLsMYJAAAAsAfByYXBqbBQpKTE7tEAAAAA8YPg5MLgZIUnAAAAALFBcHKR5GSRtDT/adY5AQAAALFDcHIZGkQAAAAAsUdwchkaRAAAAACxR3ByGSpOAAAAQOwRnFyGneACAAAAsUdwchkqTgAAAEDsEZxchjVOAAAAQOwRnFyGihMAAAAQewQnlyE4AQAAALFHcHIZmkMAAAAAsUdwchkqTgAAAEDsEZxchuYQAAAAQOwRnFyGihMAAAAQewQnl2GNEwAAABB7BCeXVpyKikQOHLB7NAAAAEB8IDi5THr6wdNUnQAAAIDYIDi5TJ06Ig0b+k8TnAAAAIDYIDi5EOucAAAAgNgiOLkQnfUAAACA2CI4uRDBCQAAAIgtgpMLsRNcAAAAILYITi5ExQkAAACILYKTC9EcAgAAAIgtgpMLUXECAAAAYovg5EKscQIAAABii+DkQlScAAAAgNgiOLkQa5wAAACA2CI4uRAVJwAAACC2CE4uRHACAAAAYovg5EI0hwAAAABii+Dk4uBUXCyyb5/dowEAAAC8j+DkQg0biiT+b8sxXQ8AAACIk+A0bdo0ycnJkdTUVOndu7esXLkyrPvNnTtXEhISZNiwYRJPNDRlZPhPE5wAAACAOAhO8+bNkzFjxsiECRNkzZo10qVLFxk0aJBs27at2vutX79ebr75ZunXr5/EI9Y5AQAAAHEUnKZMmSKjR4+WUaNGSYcOHWTGjBmSlpYms2bNqvI+JSUlcvHFF8tdd90lbdq0kXhEZz0AAAAgToLT/v37ZfXq1TJgwICDA0pMNOdXrFhR5f0mTpwoLVq0kMsvvzzkzyguLpbCwsIyBy9gJ7gAAABAnASn/Px8Uz3KzMwsc7mez83NrfQ+y5cvl2eeeUZmzpwZ1s+YNGmSZGRkBA6tW7cWL6DiBAAAAMTRVL1I7Nq1Sy655BITmpo1axbWfcaNGycFBQWBw6ZNm8QLWOMEAAAAxE4dsZGGn6SkJNm6dWuZy/V8VlZWhdt///33pinEmWeeGbistLTUHNepU0fWrVsnRx11VJn7pKSkmIPXUHECAAAA4qTilJycLN27d5clS5aUCUJ6vm/fvhVu3759e/n888/lk08+CRzOOuss+c1vfmNOe2UaXjhY4wQAAADEScVJaSvykSNHSo8ePaRXr14ydepUKSoqMl321IgRIyQ7O9usVdL9PHXq1KnM/Rv9r/RS/nKvo+IEAAAAxFFwGj58uOTl5cn48eNNQ4iuXbvKwoULAw0jNm7caDrtoSyCEwAAABA7CT6fzydxRNuRa3c9bRSRnp4ubjV/vogu9erRQ2TVKrtHAwAAAHg7G1DKcSkqTgAAAEDsEJxciuYQAAAAQOwQnDxQcYqvyZYAAABA7BGcXB6cfv1VpKjI7tEAAAAA3kZwcqm0NN3pr/800/UAAACA2kVwcqmEBNY5AQAAALFCcHIxOusBAAAAsUFwcjGCEwAAABAbBCcPBKdffrF7JAAAAIC3EZxcjIoTAAAAEBsEJxejOQQAAAAQGwQnF6PiBAAAAMQGwcnFWOMEAAAAxAbBycWoOAEAAACxQXByMdY4AQAAAA4OTps2bZLNmzcHzq9cuVJuvPFGeeqpp6I5NoRAxQkAAABwcHC66KKLZOnSpeZ0bm6unHbaaSY83XbbbTJx4sRojxFVIDgBAAAADg5OX3zxhfTq1cucfumll6RTp07ywQcfyJw5c2T27NnRHiOqQHMIAAAAwMHB6cCBA5KSkmJOL168WM466yxzun379rJly5bojhAh1zgVFIiUlto9GgAAAMC7ahScOnbsKDNmzJD//Oc/smjRIhk8eLC5/Oeff5amTZtGe4wIUXHy+UQKC+0eDQAAAOBdNQpO9913nzz55JNyyimnyIUXXihdunQxl7/55puBKXyofVr0S031n2adEwAAAFB76tTkThqY8vPzpbCwUBpb88VE5Morr5S0tLRojg8h6NOvsyMJTgAAAIDDKk579+6V4uLiQGjasGGDTJ06VdatWyctWrSI9hhRDRpEAAAAAA4NTkOHDpW//e1v5vTOnTuld+/e8tBDD8mwYcNk+vTp0R4jqsFOcAEAAACHBqc1a9ZIv379zOlXXnlFMjMzTdVJw9Sjjz4a7TGiGlScAAAAAIcGpz179kjDhg3N6XfffVfOOeccSUxMlD59+pgAhdih4gQAAAA4NDi1bdtWXn/9ddm0aZO88847MnDgQHP5tm3bJD09PdpjRDWoOAEAAAAODU7jx4+Xm2++WXJyckz78b59+waqT926dYv2GFENKk4AAACAQ9uRn3feeXLSSSfJli1bAvtwUqeeeqqcffbZ0RwfQqDiBAAAADg0OKmsrCxz2Lx5szl/2GGHsfNbG1BxAgAAABw6Va+0tFQmTpwoGRkZcsQRR5hDo0aN5O677zbXIXaoOAEAAAAOrTjddttt8swzz8jkyZPlxBNPNJctX75c7rzzTtm3b5/cc8890R4nqkDFCQAAAHBocHruuefk6aeflrPOOitwWefOnSU7O1uuueYaglMMUXECAAAAHDpVb8eOHdK+ffsKl+tleh1ih4oTAAAA4NDgpJ30Hn/88QqX62VaeULsK05794oUF9s9GgAAAMCbajRV7/7775chQ4bI4sWLA/twWrFihdkh7oIFC6I9RlRD9zeckCDi8/mrTpmZdo8IAAAA8J4aVZz69+8v33zzjdln086dO83hnHPOkS+//FKef/756I8SVUpMFMnI8J9mnRMAAABQOxJ8Pq1VRMenn34qxx9/vJSUlIhTFRYWmjbqBQUFkq7lGg9o00bkxx+16ifSp4/dowEAAADcIZJsUKOKE5yFznoAAABA7SI4eSg40VkPAAAAqB0EJw+1JKfiBAAAADigq542gKiONolA7FFxAgAAABwUnHThVKjrR4wYcahjQoSoOAEAAAAOCk7PPvts7Y0ENUbFCQAAAKhdrHHyACpOAAAAQO0iOHkAFScAAACgdhGcPICKEwAAAFC7CE4eQMUJAAAAqF0EJw+g4gQAAADULoKThypOBQUipaV2jwYAAADwHkcEp2nTpklOTo6kpqZK7969ZeXKlVXe9tVXX5UePXpIo0aNpH79+tK1a1d5/vnnJZ5ZFScNTbt22T0aAAAAwHtsD07z5s2TMWPGyIQJE2TNmjXSpUsXGTRokGzbtq3S2zdp0kRuu+02WbFihXz22WcyatQoc3jnnXckXqWmiqSk+E+zzgkAAACIvgSfz+cTG2mFqWfPnvL444+b86WlpdK6dWu5/vrr5ZZbbgnrMY4//ngZMmSI3H333SFvW1hYKBkZGVJQUCDp6eniFS1biuTminz8sUjXrnaPBgAAAHC+SLKBrRWn/fv3y+rVq2XAgAEHB5SYaM5rRSkUzXxLliyRdevWycknn1zpbYqLi80TEnzwIjrrAQAAALXH1uCUn58vJSUlkpmZWeZyPZ+r5ZMqaCJs0KCBJCcnm0rTY489Jqeddlqlt500aZJJkdZBq1leRGc9AAAAwMNrnGqiYcOG8sknn8iqVavknnvuMWukli1bVultx40bZ4KWddi0aZN4ERUnAAAAoPbUERs1a9ZMkpKSZOvWrWUu1/NZWVlV3k+n87Vt29ac1q56a9euNZWlU045pcJtU1JSzMHrqDgBAAAAHq046VS77t27m3VKFm0Ooef79u0b9uPofXQtUzyj4gQAAAB4tOKkdJrdyJEjzb6ZevXqJVOnTpWioiLTYlyNGDFCsrOzTUVJ6bHe9qijjjJhacGCBWY/TtOnT5d4RsUJAAAA8HBwGj58uOTl5cn48eNNQwiderdw4cJAw4iNGzeaqXkWDVXXXHONbN68WerVqyft27eXF154wTxOPKPiBAAAAHh4P06x5tX9OD3zjMgVV4gMGSIyf77dowEAAACczzX7cUL0UHECAAAAag/BySNY4wQAAADUHoKTR1BxAgAAAGoPwckjqDgBAAAAtYfg5LGK0969InG+SysAAAAg6ghOHpGRIZKQ4D/NdD0AAAAgughOHqG7urI6KBKcAAAAgOgiOHkI65wAAACA2kFw8hA66wEAAAC1g+DkIVScAAAAgNpBcPIQKk4AAABA7SA4ebDiRHACAAAAoovg5MGKE1P1AAAAgOgiOHkIFScAAACgdhCcPISKEwAAAFA7CE4eQsUJAAAAqB0EJw+h4gQAAADUDoKTh1BxAgAAAGoHwclDqDgBAAAAtYPg5NGKk89n92gAAAAA7yA4ebDiVFoqsmuX3aMBAAAAvIPg5CH16omkpPhPs84JAAAAiB6Ck8ewzgkAAACIPoKTx9BZDwAAAIg+gpPHUHECAAAAoo/g5DFUnAAAAIDoIzh5DBUnAAAAIPoITh5DxQkAAACIPoKTx1BxAgAAAKKP4OQxVJwAAACA6CM4eQwVJwAAAGdatUrk3XftHgVqqk6N7wlHV5wITgAAAM5y5pki+fki27aJNGli92gQKSpOHmO9Cbdvt3skAAAACKaBqaREpKDA7pGgJghOHtO0qf+Y4AQAAOAcGph8Pv/pAwfsHg1qguDk0eC0Y8fBNycAAADs9euvlZ+GexCcPBqc9FuNwkK7RwMAAIDyVSYqTu5EcPKY1FSRtDT/aabrAQAAOAPByf0ITh7EOicAAABnCQ5LTNVzJ4KTBxGcAAAAnIWKk/sRnDyIluQAYmH/frtHAADuQXByP4KTB1FxAlDb5swRadhQ5I037B4JALgDU/Xcj+Dk8ZbkAFAb3n/fX3H68EO7RwIA7kDFyf0ITh5ExQlArKbpMV0PAMJDcHI/gpMHEZwA1DYrMBUX2z0SAHAHpuq5H8HJgwhOAGobFScAiAwVJ/cjOHkQXfUA1DaCEwBEhuDkfgQnD6LiBKC2EZwAIDLB0/OYqudOBCcPoqsegNpGcAKAyFBxcj+Ck4eDU2Ehb0wAtYPgBACRoTmE+xGcPKhRI5GEBP9pqk4AagNd9QAgMlSc3M8RwWnatGmSk5Mjqamp0rt3b1m5cmWVt505c6b069dPGjdubA4DBgyo9vbxKClJpHFj/2nWOQGoDVZgouIEAOEhOLmf7cFp3rx5MmbMGJkwYYKsWbNGunTpIoMGDZJt27ZVevtly5bJhRdeKEuXLpUVK1ZI69atZeDAgfLTTz/FfOxORoMIALWJqXoAEBmm6rmf7cFpypQpMnr0aBk1apR06NBBZsyYIWlpaTJr1qxKbz9nzhy55pprpGvXrtK+fXt5+umnpbS0VJYsWRLzsTsZLckB1CaCEwBEhoqT+9kanPbv3y+rV6820+0CA0pMNOe1mhSOPXv2yIEDB6SJlRTKKS4ulsLCwjKHeEBnPQC1ieAEAJEhOLmfrcEpPz9fSkpKJDMzs8zlej43Nzesxxg7dqy0atWqTPgKNmnSJMnIyAgcdGpfPGCqHoDaRHMIAIgMU/Xcz/apeodi8uTJMnfuXHnttddMY4nKjBs3TgoKCgKHTZs2STwgOAGoTVScACAyVJzcr46dP7xZs2aSlJQkW7duLXO5ns/Kyqr2vg8++KAJTosXL5bOnTtXebuUlBRziDcEJwC1ieAEAJEhOLmfrRWn5ORk6d69e5nGDlajh759+1Z5v/vvv1/uvvtuWbhwofTo0SNGo3UXghOA2kRwAoDIMFXP/WytOCltRT5y5EgTgHr16iVTp06VoqIi02VPjRgxQrKzs81aJXXffffJ+PHj5e9//7vZ95O1FqpBgwbmAD+CE4DaRHACgMgEhyUqTu5ke3AaPny45OXlmTCkIUjbjGslyWoYsXHjRtNpzzJ9+nTTje+8884r8zi6H6g777wz5uN3KqvJIF31AERbSYnODvCfJjgBQHiYqud+tgcndd1115lDVTu8DbZ+/foYjcrdqDgBqC3BYYmuegAQHqbquZ+ru+ohvODk89k9GgBeDU5aedIKFACgelSc3I/g5PHgpB9wiorsHg0ALyk/PY/pegAQGhUn9yM4eVRamrZi959muh6AaCI4AUDkqDi5H8HJoxISdD9Z/tP5+XaPBoCXEJwAIHIEJ/cjOHlY8+b+Y4ITgGgqH5RoEAEAoTFVz/0ITh5mVZzy8uweCQAvoeIEAJGj4uR+BCcPY6oegNpAcAKAyBGc3I/g5GFM1QNQG8pPzSM4AUBoTNVzP4KThzFVD0BtoOIEAJGj4uR+BCcPY6oegNpAcAKAyAVXmQhO7kRw8jCCE4DaQFc9AIgcU/Xcj+DkYaxxAlAbqDgBQOSYqud+BCcPY40TgNpAcAKAyBGc3I/gFAfBaft2kdJSu0cDwCsITgAQOabquR/BKQ6Ck4amnTvtHg0AryA4AUDkqDi5H8HJw+rWFcnI8J9muh6AaKE5BABEjuDkfgQnj6OzHoBoo+IEAJFjqp77EZw8js56AKKN4AQAkaPi5H4EJ4+jsx6AaCM4AUDkqDi5H8HJ45iqByDaCE4AcOjByeezczSoCYKTxxGcAEQbwQkAIld+eh5VJ/chOHkca5wARBtd9QAgcuWDEsHJfQhOHscaJwDRRsUJAA694kSDCPchOHkcU/UARBvBCQAiR3ByP4KTxzFVD0C0WUEpLa3seQBA5UpL/YdgTNVzH4KTxzFVD0C0WWuaGjb0HxOcAKB6lVWXqDi5D8EpToLTrl0s4AYQHVZQatDAf8zfFgCoHsHJGwhOHpeRIZKU5D+9fbvdowHgpeBExQkAwhMckurV8x8zVc99CE4el5jIdD0AtVtxIjgBQOTBiYqT+xCc4gCd9QBEE8EJACJjhSSdBZScXPYyuAfBKQ4QnABEE8EJACJjhaS6dUXq1PGfZqqe+xCc4gAtyQFEE2ucAKDmwUkPwZfBPQhOcRSctm2zeyQAvICuegAQGSpO3kBwigMtWviPt261eyQAvICpegAQGSskUXFyN4JTHMjM9B8TnABEA8EJACLDVD1vIDjFAYITgGgiOAFAZJiq5w0EpzhAcAIQTTSHAIDIUHHyBoJTHAUnmkMAiAaaQwBAZAhO3kBwiqPmELt3i+zZY/doALgdU/UAIDJM1fMGglMc0Ok0qan+00zXA3CoCE4AULPgpKGJipN7EZziQEIC65wAREdp6cFvSQlOAFDzihPByX0ITnGC4AQgGoL/o7eCk17m89k2JABw5Ronpuq5D8EpThCcAERDcHXJ6qqn+OYUAKpGcwhvIDjFCTrrAYiG4A56VsWp/OUAgLKYqucNBKc466xHxQlANCpOSUki9epVvBwAUJE1LY+peu5GcIoTTNUDEA1WQEpO9oenxP/9L0JwAoCqMVXPGwhOcYLgBCDawSn4mOAEAFVjP07eQHCKEwQnALURnFJSyl4OAKiIipM3EJziBMEJQG1WnGgOAQBVIzh5A8EpzppD7NzJN8MAao6pegAQOabqeYPtwWnatGmSk5Mjqamp0rt3b1m5cmWVt/3yyy/l3HPPNbdPSEiQqVOnxnSsbta48cE3Ki3JAdQUwQkAIkfFyRtsDU7z5s2TMWPGyIQJE2TNmjXSpUsXGTRokGyr4pP9nj17pE2bNjJ58mTJysqK+XjdTDtf0ZIcwKEiOAFA5KyQpF9isx8n97I1OE2ZMkVGjx4to0aNkg4dOsiMGTMkLS1NZs2aVente/bsKQ888IBccMEFkmKtSEbYWOcE4FARnAAgOhUnpuq5j23Baf/+/bJ69WoZMGDAwcEkJprzK1asiNrPKS4ulsLCwjKHeEVwAnCo6KoHAJFjqp432Bac8vPzpaSkRDKtT/P/o+dzc3Oj9nMmTZokGRkZgUPr1q0lXhGcABwquuoBQHSaQxCc3Mf25hC1bdy4cVJQUBA4bNq0SeKVtcaJ5hAAaoqpegAQOabqecP/Mm/sNWvWTJKSkmRrufKHno9m4wddC8V6KD8qTgAOFcEJACJnhSSm6rmbbRWn5ORk6d69uyxZsiRwWWlpqTnft29fu4blaQQnAIeK4AQAkWOqnjfYVnFS2op85MiR0qNHD+nVq5fZL1NRUZHpsqdGjBgh2dnZZp2S1VDiq6++Cpz+6aef5JNPPpEGDRpI27Zt7fxVXMEq5G3ZYvdIALiVFZCsQj7NIQAgNKbqeYOtwWn48OGSl5cn48ePNw0hunbtKgsXLgw0jNi4caPptGf5+eefpVu3boHzDz74oDn0799fli1bZsvv4CY5Of7j9etFfD6RhAS7RwTAbWgOAQCRo6ueN9ganNR1111nDpUpH4ZycnLEp5/4USOHH+4PS3v2+BtElGtoCAAhMVUPAKIzVY+Kk/t4vqseDtIPOFY39h9+sHs0ANzIqiwRnAAgfFScvIHgFGfatPEfE5wA1AQVJwCIHM0hvIHgFGcITgAOBcEJACJnhSQNTTSHcC+CU5whOAGIZnCiqx4AhMZUPW8gOMUZghOAQ0FXPQCIHFP1vIHgFKfB6ccf7R4JADdiqh4ARI79OHkDwSnOHHmk/3jzZr4hBhA5ghMARI6pet5AcIozzZuL1K/v3wHuhg12jwaA2xCcACByVnWJqXruRnCKM7oDXNY5AagpmkMAQOSYqucNBKc4RHACUFM0hwCAyNEcwhsITnGI4ASgppiqBwCRY42TNxCc4hDBCUBNEZwAIHJM1fMGglMcoiU5gJqyApK1tongBAChMVXPGwhOcV5x0u56ABAuKk4AEL2KE5/D3IXgFIdycvzHhYUiO3bYPRoAbkJXPQCITnBSJSW2DQk1QHCKQ6mpIocd5j+9dq3dowHgJnTVA4DIlJb6D0qn6VlT9RTT9dyF4BSnunXzH69ZY/dIAHih4rRvn31jAgAnCw5H5StONIhwF4JTnDr+eP/x6tV2jwSAm4NTo0b+45077RsTALg1OFFxcheCU5zq3t1/TMUJQCSsypIVnBo3Prhmkm9OASB0cEpKqvw6OB/BKc6D01dfiezZY/doALiBztEvKChbabKOFVUnAKgo+EslDU4JCQfXOfGFk7sQnOJUq1YiWVn+D0Kffmr3aAC4gVaVrNa5VqVJPwQ0bOg//csv9o0NAJzKqipppUlDk2JfTu5EcIpjrHMCEAlr9wX16h1sChEcoghOAFB9K3KLdZrg5C4EpzhmTdcjOAEIhxWMrKBkadLEf8x+4QAgsuDEVD13ITjFMRpEAKhJcLKCkoWKEwBEFpyYqudOBKc4ZgWnL78U2bvX7tEAcGvFyTpPxQkAKmKqnncQnOJYdrZI8+YiJSUin31m92gAuH2qHhUnAKiIqXreQXCKY9rZhXVOAMJlVZSqqjgRnACgIqbqeQfBKc716uU/fu89u0cCwOloDgEAkbPCkRWWFBUndyI4xbmBA/3H777rn7IHAFWhOQQARI41Tt5BcIpzvXuLNGrk/8CzapXdowHgZDSHAIDIMVXPOwhOcU7fuKed5j/99tt2jwaAk9EcAgAiR3MI7yA4QQYP9h8vXGj3SAA4Gc0hACByVjii4uR+BCcEgpNO1cvLs3s0AJyK5hAAELldu/zHaWkHL2ONkzsRnCCtWol07izi84ksWmT3aAC4tTmE7kh7377YjwsAnOynnw7uP9PCVD13IjjBYLoegOpo182CgsorTunp/v3CKabrAUBZmzf7jw877OBlTNVzJ4ITjNNP9x+/+ebBD0cAYAn+u1A+OCUmss4JAKqyaVPF4MRUPXciOMHo10/k2GP9H44ee8zu0QBwGmv9Uv36ZRc4WwhOAFB9xal164OXMVXPnQhOMJKSRG6/3X96ypSDCxkBoLrGEBYaRABA5Ziq5x0EJwQMHy7Srp3/A9Ljj9s9GgBuaAxhoeIEABUVF4ts2+Y/zVQ99yM4odKq00MPUXUCEH7FybqcihMAVOyol5oq0rTpwctTUvzH7AbGXQhOKOOCC0SOOUZk+3aRhx+2ezQA3DZVj4oTAFQ+Tc/qPqoGDPAfz5nDOic3ITihDJ1zO3Gi//QDD/BNCICylaRQFSeCEwBUv75JnX22SLNm/orUW2/ZMjTUAMEJFfz+9yLHHy+ye7fIvffaPRoATkBzCACIXnDSqXqXXeY/PWNG7MeFmiE4oQLdJ8vkyf7TTzwhsmGD3SMCYDeaQwBAdFqRW6680n/8zjsiP/wQ23GhZghOqNRpp4mceqrI/v0il17q7woDIH7RHAIAorPzW8tRR4kMHCji84nMnBnzoaEGCE6o0iOPiDRoILJsmcioUSKlpXaPCIBdaA4BANGbqmf54x/9x889x+csNyA4oUodO4q8+qq/YcSLL4rceKNISYndowJgB5pDAED0g9OQISIZGSJbtoi8/35Mh4YaIDgh5JS9WbP8px97TOT00+m0B8SjSJpD6LQTAIh3utxh69aq1zhZTSKGDfOffuml2I0NNUNwQkiXXCLywgsiaWkiixaJdOkiMmUK3ywD8STc5hC6P5KiotiNCwCc6uef/V8kJSf7W49X5fzz/cevvMLMHqcjOCEsF18ssnKlSPv2/nLyTTeJZGf790MwfbrIF1/4v1kB4D0ahnbtqr7ipF+s1K3rP02DCACoeue35enOcBs1EsnNFVm+PGbDg1uD07Rp0yQnJ0dSU1Old+/eslI/oVfj5Zdflvbt25vbH3fccbJgwYKYjTXe1zytWePv/NK5s8jevSKvvy5yzTUixx0nUr++SIcO/v1A3XmnyOzZIu++K/LllyI7dzJ9B3Arff9a9D/3yuiHAqsatX59bMYFAG5e32TRipR+Ea1efrn2x4WaqyM2mzdvnowZM0ZmzJhhQtPUqVNl0KBBsm7dOmnRokWF23/wwQdy4YUXyqRJk+SMM86Qv//97zJs2DBZs2aNdOrUyZbfIZ7UqydyxRUil1/uD1G67wENR3pav5Feu9Z/0HJzeamp/g9W+o118EE/iOmxBi/91to6lD+vB50LrH9g9JttPVindd9TAGp3ml7Dhv5mMVXRHWe//bbIeef5/zZ06xazIQKAq/bhVNl0vWef9Qena68VOfbYWh8eaiDB57O3DqBhqWfPnvL444+b86WlpdK6dWu5/vrr5ZZbbqlw++HDh0tRUZHMnz8/cFmfPn2ka9euJnyFUlhYKBkZGVJQUCDp6elR/m3il76K9A+EVpe++sp/0H0X6Pzen36q/fVQSUkVw1Twaf2wp7fRgKUH63S4l4W6Xr9tt8rwlZ0OdT6S20bj5wSrbPpANC/j8WvvZ1alur/q4fzFD3796O2/+07k/vtFDj+8+h1ib9smMniwyMcfi+if15NPPvherOoQ/B6qyXGo2wQ/b9U9z+Fe54bHiJZofjrgsWL/ODyWfY+lj6OtxefO9X+5PHasyOTJ1d/nwAH/EgirAZeuJ2/ZsuLnmvKfb4I/k1T2dzHUdZXdrrLPENZxwiFcVtl1Q4f6v1i3UyTZwNaK0/79+2X16tUybty4wGWJiYkyYMAAWbFiRaX30cu1QhVMK1Sv65yxShQXF5tD8JOD6NMXv36jogf94FSeTuvTubsaoCo76FSgPXvKHnSBefnzuo6qsrVUuphSD/v2xeTXBeJSZmb11+skAd3v21lnifz73yJB328BQNw64ojQt9EQpBX7u+7yH3/6qf/gdbm59genSNganPLz86WkpEQyy/1vrOe//vrrSu+Tm5tb6e318srolL679FUI26f4HXmk/xCNb3I0JOm3Mxqi9Liq09axLm7Xb3/0fnpc1emaXK/H1rdUelz+dKjzkdw2Gj+n/HNZ2fMbrct4/Nr9mdVVGWp6XfDrx/q5+v7VqbI6TTcU/bJOp+np0lNtEmG9J6s6WO8ffS/V9Li666p6DoPPh3udWx4jmtUnHsuex3LimHisyB9Hw5B+oTR8eHj36d5d5M039fOxyNKl/i+Ngz/bVPZZJ/hvaKi/i5GcLv+54VAvq+o6q6mQW9i+xqm2aTUruEKlFSedCgj30j9GOvVOD/qBDoCz6FpEa6EzACAy2rpcG23BeWwNTs2aNZOkpCTZau0d7H/0fFZWVqX30csjuX1KSoo5AAAAAEBN2dqLLDk5Wbp37y5LliwJXKbNIfR83759K72PXh58e7Vo0aIqbw8AAAAArp+qp9PoRo4cKT169JBevXqZduTaNW/UqFHm+hEjRkh2drZZq6RuuOEG6d+/vzz00EMyZMgQmTt3rnz00Ufy1FNP2fybAAAAAPAq24OTthfPy8uT8ePHmwYP2lZ84cKFgQYQGzduNJ32LCeccILZd9Ptt98ut956qxx99NGmox77cAIAAADg2f04xRr7cQIAAAAQaTawdY0TAAAAALgBwQkAAAAAQiA4AQAAAEAIBCcAAAAACIHgBAAAAAAhEJwAAAAAIASCEwAAAACEQHACAAAAgBAITgAAAAAQAsEJAAAAAEIgOAEAAABACAQnAAAAAAiB4AQAAAAAIdSROOPz+cxxYWGh3UMBAAAAYCMrE1gZoTpxF5x27dpljlu3bm33UAAAAAA4JCNkZGRUe5sEXzjxykNKS0vl559/loYNG0pCQoJtyVaD26ZNmyQ9Pd2WMSD62K7exHb1Jrar97BNvYnt6k2FDtquGoU0NLVq1UoSE6tfxRR3FSd9Qg477DBxAn2h2P1iQfSxXb2J7epNbFfvYZt6E9vVm9Idsl1DVZosNIcAAAAAgBAITgAAAAAQAsHJBikpKTJhwgRzDO9gu3oT29Wb2K7ewzb1JrarN6W4dLvGXXMIAAAAAIgUFScAAAAACIHgBAAAAAAhEJwAAAAAIASCEwAAAACEQHCywbRp0yQnJ0dSU1Old+/esnLlSruHhDDdeeedkpCQUObQvn37wPX79u2Ta6+9Vpo2bSoNGjSQc889V7Zu3WrrmFHRe++9J2eeeabZS7huw9dff73M9dozZ/z48dKyZUupV6+eDBgwQL799tsyt9mxY4dcfPHFZsd9jRo1kssvv1x2794d498EkWzXSy+9tML7d/DgwWVuw3Z1lkmTJknPnj2lYcOG0qJFCxk2bJisW7euzG3C+bu7ceNGGTJkiKSlpZnH+ctf/iK//vprjH8bRLJdTznllArv16uuuqrMbdiuzjJ9+nTp3LlzYKe2ffv2lbfffttT71WCU4zNmzdPxowZY1owrlmzRrp06SKDBg2Sbdu22T00hKljx46yZcuWwGH58uWB6/785z/LP//5T3n55Zfl3//+t/z8889yzjnn2DpeVFRUVGTee/olRmXuv/9+efTRR2XGjBny3//+V+rXr2/ep/pH36Ifrr/88ktZtGiRzJ8/33xov/LKK2P4WyDS7ao0KAW/f1988cUy17NdnUX/juoHrQ8//NBskwMHDsjAgQPNtg73725JSYn5ILZ//3754IMP5LnnnpPZs2ebL0fg3O2qRo8eXeb9qn+bLWxX5znssMNk8uTJsnr1avnoo4/kt7/9rQwdOtT8TfXMe1XbkSN2evXq5bv22msD50tKSnytWrXyTZo0ydZxITwTJkzwdenSpdLrdu7c6atbt67v5ZdfDly2du1abffvW7FiRQxHiUjo9nnttdcC50tLS31ZWVm+Bx54oMy2TUlJ8b344ovm/FdffWXut2rVqsBt3n77bV9CQoLvp59+ivFvgHC2qxo5cqRv6NChVd6H7ep827ZtM9vo3//+d9h/dxcsWOBLTEz05ebmBm4zffp0X3p6uq+4uNiG3wKhtqvq37+/74YbbqjyPmxXd2jcuLHv6aef9sx7lYpTDGmC1hSu034siYmJ5vyKFStsHRvCp1O2dCpQmzZtzLfTWlZWum31W7Pg7avT+A4//HC2r4v8+OOPkpubW2Y7ZmRkmGm11nbUY53G1aNHj8Bt9Pb6ftYKFZxr2bJlZvpHu3bt5Oqrr5bt27cHrmO7Ol9BQYE5btKkSdh/d/X4uOOOk8zMzMBttIJcWFgY+CYcztquljlz5kizZs2kU6dOMm7cONmzZ0/gOrars5WUlMjcuXNNFVGn7HnlvVrH7gHEk/z8fPNCCn5BKD3/9ddf2zYuhE8/PGvZWD906bSBu+66S/r16ydffPGF+bCdnJxsPniV3756HdzB2laVvU+t6/RYP3wHq1OnjvlPn23tXDpNT6eFHHnkkfL999/LrbfeKqeffrr5zzopKYnt6nClpaVy4403yoknnmg+SKtw/u7qcWXvZ+s6OG+7qosuukiOOOII80XlZ599JmPHjjXroF599VVzPdvVmT7//HMTlHRqu65jeu2116RDhw7yySefeOK9SnACIqAfsiy6AFKDlP5hf+mll0wTAQDOdcEFFwRO67ea+h4+6qijTBXq1FNPtXVsCE3XxOiXVMHrSuHd7Rq8tlDfr9qsR9+n+qWHvm/hTO3atTMhSauIr7zyiowcOdKsZ/IKpurFkJab9VvN8h1E9HxWVpZt40LN6TcnxxxzjHz33XdmG+p0zJ07d5a5DdvXXaxtVd37VI/LN3TRrj/akY1t7R463Vb/Luv7V7Fdneu6664zzTqWLl1qFqBbwvm7q8eVvZ+t6+C87VoZ/aJSBb9f2a7Ok5ycLG3btpXu3bub7onasOeRRx7xzHuV4BTjF5O+kJYsWVKmRK3ntawJ99E2xfrtl34Tptu2bt26ZbavTivQNVBsX/fQaVz6Bzp4O+r8al3jYm1HPdY//jpn2/Kvf/3LvJ+t/9zhfJs3bzZrnPT9q9iuzqN9PvTDtU730W2h789g4fzd1WOdPhQcirWTm7ZL1ilEcN52rYxWMVTw+5Xt6nylpaVSXFzsnfeq3d0p4s3cuXNNd67Zs2ebDk5XXnmlr1GjRmU6iMC5brrpJt+yZct8P/74o+/999/3DRgwwNesWTPTEUhdddVVvsMPP9z3r3/9y/fRRx/5+vbtaw5wll27dvk+/vhjc9A/g1OmTDGnN2zYYK6fPHmyeV++8cYbvs8++8x0YjvyyCN9e/fuDTzG4MGDfd26dfP997//9S1fvtx39NFH+y688EIbfytUt131uptvvtl0b9L37+LFi33HH3+82W779u0LPAbb1VmuvvpqX0ZGhvm7u2XLlsBhz549gduE+rv766+/+jp16uQbOHCg75NPPvEtXLjQ17x5c9+4ceNs+q0Qart+9913vokTJ5rtqe9X/Vvcpk0b38knnxx4DLar89xyyy2mM6JuM/2/U89rV9J3333XM+9VgpMNHnvsMfPCSU5ONu3JP/zwQ7uHhDANHz7c17JlS7PtsrOzzXn9A2/RD9bXXHONab+ZlpbmO/vss81/BnCWpUuXmg/W5Q/artpqSX7HHXf4MjMzzRcdp556qm/dunVlHmP79u3mA3WDBg1Mq9RRo0aZD+dw5nbVD2T6n7H+J6wtcY844gjf6NGjK3xpxXZ1lsq2px6effbZiP7url+/3nf66af76tWrZ77s0i/BDhw4YMNvhHC268aNG01IatKkifkb3LZtW99f/vIXX0FBQZnHYbs6y2WXXWb+tupnJP1bq/93WqHJK+/VBP3H7qoXAAAAADgZa5wAAAAAIASCEwAAAACEQHACAAAAgBAITgAAAAAQAsEJAAAAAEIgOAEAAABACAQnAAAAAAiB4AQAAAAAIRCcAACoRkJCgrz++ut2DwMAYDOCEwDAsS699FITXMofBg8ebPfQAABxpo7dAwAAoDoakp599tkyl6WkpNg2HgBAfKLiBABwNA1JWVlZZQ6NGzc212n1afr06XL66adLvXr1pE2bNvLKK6+Uuf/nn38uv/3tb831TZs2lSuvvFJ2795d5jazZs2Sjh07mp/VsmVLue6668pcn5+fL2effbakpaXJ0UcfLW+++Wbgul9++UUuvvhiad68ufkZen35oAcAcD+CEwDA1e644w4599xz5dNPPzUB5oILLpC1a9ea64qKimTQoEEmaK1atUpefvllWbx4cZlgpMHr2muvNYFKQ5aGorZt25b5GXfddZecf/758tlnn8nvfvc783N27NgR+PlfffWVvP322+bn6uM1a9Ysxs8CAKC2Jfh8Pl+t/xQAAGq4xumFF16Q1NTUMpffeuut5qAVp6uuusqEFUufPn3k+OOPlyeeeEJmzpwpY8eOlU2bNkn9+vXN9QsWLJAzzzxTfv75Z8nMzJTs7GwZNWqU/PWvf610DPozbr/9drn77rsDYaxBgwYmKOk0wrPOOssEJa1aAQC8izVOAABH+81vflMmGKkmTZoETvft27fMdXr+k08+Mae1AtSlS5dAaFInnniilJaWyrp160wo0gB16qmnVjuGzp07B07rY6Wnp8u2bdvM+auvvtpUvNasWSMDBw6UYcOGyQknnHCIvzUAwGkITgAAR9OgUn7qXLTomqRw1K1bt8x5DVwavpSur9qwYYOpZC1atMiEMJ369+CDD9bKmAEA9mCNEwDA1T788MMK54899lhzWo917ZNOr7O8//77kpiYKO3atZOGDRtKTk6OLFmy5JDGoI0hRo4caaYVTp06VZ566qlDejwAgPNQcQIAOFpxcbHk5uaWuaxOnTqBBgza8KFHjx5y0kknyZw5c2TlypXyzDPPmOu0icOECRNMqLnzzjslLy9Prr/+ernkkkvM+iall+s6qRYtWpjq0a5du0y40tuFY/z48dK9e3fTlU/HOn/+/EBwAwB4B8EJAOBoCxcuNC3Cg2m16Ouvvw50vJs7d65cc8015nYvvviidOjQwVyn7cPfeecdueGGG6Rnz57mvK5HmjJlSuCxNFTt27dPHn74Ybn55ptNIDvvvPPCHl9ycrKMGzdO1q9fb6b+9evXz4wHAOAtdNUDALiWrjV67bXXTEMGAABqE2ucAAAAACAEghMAAAAAhMAaJwCAazHbHAAQK1ScAAAAACAEghMAAAAAhEBwAgAAAIAQCE4AAAAAEALBCQAAAABCIDgBAAAAQAgEJwAAAAAIgeAEAAAAAFK9/wfkGuduEtK6ZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.904761904761905%\n",
      "Precision: 0.5454545454545454\n",
      "Recall: 0.6666666666666666\n",
      "F1-Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "model.eval() \n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:                            # Iterate over each batch (i.e. one patient)\n",
    "        patient_features = data.x                       # Get features (shape: [num_nodes, in_channels])\n",
    "        patient_edges = data.edge_index                 # Get edges (shape: [2, num_edges])\n",
    "        patient_label = data.y.float()                  # Get label (shape: [1])\n",
    "\n",
    "        # Ensure correct format\n",
    "        patient_features = patient_features.float()    \n",
    "        patient_edges = patient_edges.to(torch.long)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(patient_features, patient_edges, data.batch)  # Use the batch info to aggregate across nodes\n",
    "\n",
    "        # Apply sigmoid to the output logits and get the predicted class (0 or 1)\n",
    "        pred = torch.sigmoid(output.squeeze())\n",
    "        predicted_class = (pred >= 0.5).float()                     # Threshold at 0.5 to classify as 0 or 1\n",
    "        \n",
    "        # Collect the labels and predictions for metrics\n",
    "        all_labels.append(patient_label.cpu().numpy())\n",
    "        all_predictions.append(predicted_class.cpu().numpy())\n",
    "\n",
    "        # Count correct predictions\n",
    "        correct += (predicted_class == patient_label).sum().item()\n",
    "        total += patient_label.size(0)  # Increment by the number of samples in this batch\n",
    "\n",
    "# Accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy}%\")\n",
    "\n",
    "# Calculate Metrics\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
