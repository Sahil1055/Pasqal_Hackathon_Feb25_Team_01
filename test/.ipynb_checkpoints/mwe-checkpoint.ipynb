{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Quantum AI for Multimodal Liver Cancer Prediction\n",
    "\n",
    "### Team QScreen\n",
    "\n",
    "<img src=\"https://img.shields.io/badge/Status-Research-blue\" alt=\"Status\"/> <img src=\"https://img.shields.io/badge/Framework-PyTorch-orange\" alt=\"Framework\"/> <img src=\"https://img.shields.io/badge/Application-Healthcare-green\" alt=\"Application\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Overview\n",
    "\n",
    "This notebook demonstrates our quantum-enhanced multimodal approach for liver cancer progression prediction. Our model combines clinical data with quantum-embedded medical images to predict whether a patient's condition will remain stable (censored) or progress (progressed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Introduction\n",
    "\n",
    "Liver cancer is one of the leading causes of cancer-related deaths worldwide. Early and accurate prediction of disease progression is crucial for effective treatment planning and improving patient outcomes.\n",
    "\n",
    "Our approach leverages the power of quantum computing to enhance medical image analysis, combined with traditional clinical data processing. This multimodal approach provides a more comprehensive view of the patient's condition, leading to more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup\n",
    "\n",
    "Let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Loading Test Results\n",
    "\n",
    "Let's load the results from our model's test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test results\n",
    "results_path = \"../results/results_epoch_50.pkl\"  # Adjust path as needed\n",
    "\n",
    "# Load the results\n",
    "try:\n",
    "    with open(results_path, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    print(\"Results loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Results file not found at {results_path}\")\n",
    "    # Create dummy results for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    results = {\n",
    "        'predictions': np.random.rand(n_samples, 1),\n",
    "        'labels': np.random.randint(0, 2, (n_samples, 1)),\n",
    "        'accuracy': 0.85,\n",
    "        'precision': 0.83,\n",
    "        'recall': 0.87,\n",
    "        'f1_score': 0.85\n",
    "    }\n",
    "    print(\"Created dummy results for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Model Performance\n",
    "\n",
    "Let's examine the performance of our binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions and labels\n",
    "predictions = results['predictions']\n",
    "labels = results['labels']\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['precision']:.4f}\")\n",
    "print(f\"Recall: {results['recall']:.4f}\")\n",
    "print(f\"F1 Score: {results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
