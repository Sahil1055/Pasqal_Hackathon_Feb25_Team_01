{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Clinical Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model for classification\n",
    "class PVEMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, embedding_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim, embedding_dim))\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.classifier = nn.Linear(input_dim * embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = x.unsqueeze(-1) * self.weight + self.bias\n",
    "        flattened_embeddings = embeddings.reshape(x.shape[0], -1)\n",
    "        flattened_embeddings = self.dropout(flattened_embeddings)\n",
    "        logits = self.classifier(flattened_embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([84, 38])\n",
      "Test data shape: torch.Size([21, 38])\n",
      "Train data shape: torch.Size([84])\n",
      "Test data shape: torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "# Load training data and labels\n",
    "train_data = torch.tensor(pd.read_csv(\"../data/train_data.csv\").values, dtype=torch.float32)\n",
    "train_labels_df = pd.read_csv(\"../data/labels/train_labels.csv\")\n",
    "train_labels = torch.tensor(train_labels_df.iloc[:, 1].values, dtype=torch.long)\n",
    "\n",
    "# Load test data and labels\n",
    "test_data = torch.tensor(pd.read_csv(\"../data/test_data.csv\").values, dtype=torch.float32)\n",
    "test_labels_df = pd.read_csv(\"../data/labels/test_labels.csv\")\n",
    "test_labels = torch.tensor(test_labels_df.iloc[:, 1].values, dtype=torch.long)\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Train data shape: {train_labels.shape}\")\n",
    "print(f\"Test data shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0228e+00, -3.1097e-02, -5.9342e-01,  2.4495e-01,  3.9900e-02,\n",
       "         -2.2204e+00, -8.4982e-01, -1.1445e+00, -7.3764e-01,  8.8298e-01,\n",
       "         -1.0690e+00, -7.0711e-01,  1.0418e+00, -9.1867e-01, -4.5763e-01,\n",
       "         -3.7291e-01, -1.6604e-01, -3.3002e-01, -4.5499e-01, -7.8446e-01,\n",
       "          1.7245e+00,  5.3873e-01, -6.4273e-03,  1.7578e+00,  8.6550e-01,\n",
       "         -2.4494e-02,  1.0730e-01,  9.5542e-01,  7.4422e-02,  1.7029e+00,\n",
       "          3.7984e-01, -2.5546e-01,  1.1329e+00,  1.1187e-01, -9.1631e-02,\n",
       "          2.1176e+00,  4.7410e-01, -3.7855e-01],\n",
       "        [-6.5986e-01, -1.3521e-01, -9.3057e-02, -3.3368e-01,  1.6917e-01,\n",
       "          8.2058e-01,  1.2875e+00,  1.0015e+00,  1.3557e+00, -1.1325e+00,\n",
       "         -1.0690e+00,  1.4142e+00,  1.0418e+00,  4.0707e+00, -4.5763e-01,\n",
       "          8.4294e-17, -1.6616e-01, -1.1752e+00, -9.7427e-01,  1.9612e+00,\n",
       "         -3.2027e+00, -9.0713e-02, -1.4906e-01,  3.9258e-02,  7.7607e-02,\n",
       "         -2.4494e-02,  1.0730e-01, -3.3264e-02,  7.4422e-02,  1.0475e-01,\n",
       "          1.2749e-01, -2.5546e-01, -2.7665e-02, -1.0039e+00, -1.3483e+00,\n",
       "          8.0192e-02,  2.3180e-01,  1.0046e+00],\n",
       "        [ 1.6167e+00,  4.4618e-02, -1.3976e-01,  1.2818e+00, -4.5804e-03,\n",
       "         -1.9308e-01,  1.6437e+00,  1.0015e+00, -7.3764e-01, -1.1325e+00,\n",
       "         -1.0690e+00, -7.0711e-01, -1.3362e+00,  7.4444e-01, -4.5763e-01,\n",
       "          8.4294e-17, -1.6608e-01, -1.1752e+00, -9.7427e-01,  5.8835e-01,\n",
       "          1.7245e+00, -3.3979e-01, -4.7294e-01,  1.6975e-01,  2.5081e-02,\n",
       "         -2.4494e-02,  1.0730e-01,  5.9532e-03,  7.4422e-02, -9.6851e-02,\n",
       "         -5.0814e-01, -2.5546e-01, -5.3470e-03, -2.8331e-01, -9.1631e-02,\n",
       "          2.7619e-01, -5.0266e-01, -3.7855e-01],\n",
       "        [-1.5177e+00, -1.6117e+00,  2.1717e-01,  6.2164e-01, -6.6901e-01,\n",
       "         -1.9308e-01,  3.0787e-01,  1.0015e+00, -7.3764e-01,  8.8298e-01,\n",
       "          9.3541e-01, -7.0711e-01,  1.0418e+00,  7.4444e-01, -4.5763e-01,\n",
       "         -1.3158e+00, -1.6452e-01, -3.3002e-01, -4.5499e-01,  5.8835e-01,\n",
       "          1.7245e+00,  1.3200e+00,  4.0615e-02,  6.9614e-01,  6.8901e-01,\n",
       "         -2.4494e-02,  1.0730e-01,  7.4076e-01,  7.4422e-02,  9.5242e-01,\n",
       "          2.7509e-01, -2.5546e-01,  7.0882e-01,  7.8601e-01,  1.1650e+00,\n",
       "          1.3000e+00,  7.4668e-01, -3.7855e-01],\n",
       "        [-1.6496e+00, -1.8253e-01, -4.4998e-01, -7.4532e-01, -1.0235e+00,\n",
       "         -1.9308e-01, -1.2951e+00, -1.1445e+00, -7.3764e-01,  8.8298e-01,\n",
       "          9.3541e-01, -7.0711e-01, -1.3362e+00, -9.1867e-01, -4.5763e-01,\n",
       "          8.4294e-17, -1.3971e-01,  2.2055e+00,  1.6221e+00,  5.8835e-01,\n",
       "          1.7245e+00,  3.2957e+00,  5.3923e+00,  1.8352e+00,  2.0652e+00,\n",
       "         -2.4494e-02,  1.0730e-01,  1.3187e+00,  7.4422e-02,  2.2033e+00,\n",
       "          3.0366e+00,  9.7075e-01,  2.8478e-01,  1.9483e+00,  2.4217e+00,\n",
       "          1.5425e+00,  2.3898e+00,  1.0046e+00],\n",
       "        [ 1.1548e+00, -1.6360e-01,  6.2246e-01, -6.7542e-01, -3.8683e-01,\n",
       "          8.2058e-01,  1.1984e+00,  1.0015e+00,  1.3557e+00,  8.8298e-01,\n",
       "         -1.0690e+00,  1.4142e+00,  1.5174e+00,  7.4444e-01,  1.9449e+00,\n",
       "          8.4294e-17, -1.6584e-01, -3.3002e-01, -9.7427e-01,  5.8835e-01,\n",
       "          4.9272e-01,  1.5697e-01, -2.1846e-01, -6.0269e-02,  5.8698e-02,\n",
       "         -2.4494e-02,  1.0730e-01,  1.3186e-01,  7.4422e-02,  1.2175e-01,\n",
       "          6.7972e-02, -2.5546e-01,  3.9289e-02,  1.8888e-02, -9.1631e-02,\n",
       "          2.4009e-01,  1.2580e-01, -3.7855e-01],\n",
       "        [ 5.2789e-01, -1.8253e-01, -1.1641e-01, -7.4920e-01,  2.8102e+00,\n",
       "         -1.2067e+00, -1.2060e+00, -1.1445e+00, -7.3764e-01, -1.1325e+00,\n",
       "          9.3541e-01,  1.4142e+00,  9.0591e-02, -9.1867e-01, -4.5763e-01,\n",
       "         -7.3555e-01, -1.3921e-01, -3.3002e-01, -9.7427e-01, -2.1573e+00,\n",
       "          4.9272e-01, -6.5595e-01, -6.2337e-01, -9.7150e-01, -1.0443e+00,\n",
       "         -2.4494e-02,  1.0730e-01, -1.0261e+00, -2.2823e+00, -8.7895e-01,\n",
       "         -1.1033e+00, -1.4817e+00, -9.6501e-01, -1.0039e+00, -1.3483e+00,\n",
       "         -1.2144e+00, -1.0933e+00, -1.7617e+00],\n",
       "        [-2.9694e-01,  5.4082e-02,  1.9382e-01,  7.0196e-02, -5.3695e-01,\n",
       "         -2.2204e+00, -9.3888e-01, -1.1445e+00, -7.3764e-01, -1.1325e+00,\n",
       "         -1.0690e+00,  1.4142e+00,  1.0418e+00,  7.4444e-01, -4.5763e-01,\n",
       "          8.6009e-01, -1.6612e-01, -3.3002e-01,  6.4292e-02,  5.8835e-01,\n",
       "         -7.3908e-01, -5.0654e-01, -3.8682e-01, -1.5095e-01,  2.4359e-01,\n",
       "          2.3270e+00,  1.0730e-01,  1.0709e-01,  2.4311e+00, -1.9158e-01,\n",
       "          4.3697e-01,  9.7075e-01,  3.9637e-01, -1.2059e-01, -9.1631e-02,\n",
       "         -6.2644e-01, -5.9604e-01, -3.7855e-01],\n",
       "        [ 1.7156e+00, -1.5413e-01,  1.8349e-16,  4.0028e-01, -7.1301e-02,\n",
       "          8.2058e-01, -8.4982e-01, -1.1445e+00, -7.3764e-01,  8.8298e-01,\n",
       "          9.3541e-01,  1.4142e+00,  1.0418e+00, -9.1867e-01, -4.5763e-01,\n",
       "         -1.0264e-02, -1.6612e-01, -3.3002e-01,  6.4292e-02, -7.8446e-01,\n",
       "          4.9272e-01, -5.2814e-01, -3.5996e-01, -5.0040e-01, -3.8042e-01,\n",
       "         -2.4494e-02,  1.0730e-01, -5.3905e-02,  7.4422e-02, -4.2718e-01,\n",
       "         -2.2961e-01, -2.5546e-01, -5.3470e-03, -1.4384e-01, -9.1631e-02,\n",
       "         -3.9176e-01,  2.6461e-01,  1.0046e+00],\n",
       "        [ 1.0228e+00, -2.0146e-01,  1.8349e-16, -3.3756e-01,  2.0440e-02,\n",
       "          8.2058e-01,  3.9692e-01,  1.0015e+00,  1.3557e+00,  8.8298e-01,\n",
       "          9.3541e-01,  1.4142e+00, -1.3362e+00,  7.4444e-01, -4.5763e-01,\n",
       "          8.4294e-17, -1.6525e-01, -1.1752e+00, -9.7427e-01,  5.8835e-01,\n",
       "          4.9272e-01, -8.1782e-01, -6.1574e-01, -1.0511e+00, -1.1326e+00,\n",
       "         -2.3760e+00,  1.0730e-01, -9.7035e-01,  7.4422e-02, -1.2238e+00,\n",
       "         -9.3904e-01, -2.5546e-01, -9.2038e-01, -1.0039e+00, -1.3483e+00,\n",
       "         -1.1861e+00, -7.2729e-01, -3.7855e-01],\n",
       "        [-5.2789e-01, -1.8253e-01,  7.3731e-02, -6.2493e-01, -3.2289e-01,\n",
       "          8.2058e-01,  1.2875e+00,  1.0015e+00, -7.3764e-01,  8.8298e-01,\n",
       "          9.3541e-01,  1.4142e+00,  1.0418e+00, -9.1867e-01,  1.9449e+00,\n",
       "          2.6733e+00, -1.6613e-01,  1.3603e+00,  6.4292e-02, -7.8446e-01,\n",
       "         -7.3908e-01,  2.4855e+00,  9.8955e-01,  1.5631e+00,  1.4118e+00,\n",
       "         -2.4494e-02,  1.0730e-01,  1.3806e+00,  7.4422e-02,  1.9045e+00,\n",
       "          1.5368e+00,  9.7075e-01,  1.6908e+00,  2.6225e+00,  1.1650e+00,\n",
       "          1.6456e+00,  2.2383e+00,  1.0046e+00],\n",
       "        [-1.2537e+00,  6.3547e-02,  1.7183e+00, -4.3853e-01, -7.7187e-01,\n",
       "          8.2058e-01,  1.5546e+00,  1.0015e+00,  1.3557e+00, -1.1325e+00,\n",
       "         -1.0690e+00,  1.4142e+00, -3.8501e-01, -9.1867e-01,  1.9449e+00,\n",
       "         -1.1906e-01, -1.6612e-01, -3.3002e-01, -9.7427e-01, -7.8446e-01,\n",
       "         -7.3908e-01, -6.4661e-01, -5.2134e-01, -5.5569e-01, -6.6196e-01,\n",
       "         -2.4494e-02,  1.0730e-01, -6.4629e-01,  7.4422e-02, -5.1462e-01,\n",
       "         -4.8672e-01, -2.5546e-01, -5.4097e-01, -1.0039e+00, -1.3483e+00,\n",
       "         -4.3818e-01, -2.8813e-01, -3.7855e-01],\n",
       "        [-1.3527e+00, -1.8253e-01,  5.5074e-01, -6.0940e-01, -1.0443e+00,\n",
       "          8.2058e-01,  4.8598e-01,  1.0015e+00, -7.3764e-01, -1.1325e+00,\n",
       "         -1.0690e+00,  1.4142e+00, -3.8501e-01,  7.4444e-01, -4.5763e-01,\n",
       "         -1.6784e+00, -1.6598e-01, -3.3002e-01, -4.5499e-01,  5.8835e-01,\n",
       "          1.7245e+00, -1.8998e-02, -4.7952e-01,  3.5553e-01, -8.7626e-01,\n",
       "         -2.3760e+00, -2.4679e+00, -1.6743e-01,  7.4422e-02,  5.7837e-01,\n",
       "         -4.5577e-01, -2.5546e-01,  1.0624e-01, -2.3682e-01, -9.1631e-02,\n",
       "          1.7046e-01, -6.2381e-01, -3.7855e-01],\n",
       "        [-1.1218e+00, -1.9199e-01, -1.1641e-01,  3.5246e-02, -5.7727e-01,\n",
       "         -1.9308e-01,  9.3124e-01,  1.0015e+00, -7.3764e-01,  8.8298e-01,\n",
       "         -1.0690e+00, -7.0711e-01, -1.3362e+00,  7.4444e-01, -4.5763e-01,\n",
       "          8.4294e-17, -1.6611e-01, -1.1752e+00, -9.7427e-01,  5.8835e-01,\n",
       "         -7.3908e-01, -4.8289e-01, -4.5348e-01, -5.4021e-01, -7.2709e-01,\n",
       "         -2.4494e-02,  1.0730e-01, -6.1533e-01,  7.4422e-02, -5.5105e-01,\n",
       "         -3.4626e-01, -2.5546e-01, -7.4183e-01, -2.8331e-01,  1.1650e+00,\n",
       "         -5.4907e-01, -2.5784e-01,  1.0046e+00],\n",
       "        [-7.5884e-01, -2.0146e-01, -4.9835e-01, -5.7056e-01, -2.1586e-01,\n",
       "          8.2058e-01,  8.4219e-01,  1.0015e+00, -7.3764e-01, -1.1325e+00,\n",
       "         -1.0690e+00,  1.4142e+00, -1.3362e+00,  7.4444e-01,  1.9449e+00,\n",
       "         -5.9050e-01, -1.6543e-01,  1.3603e+00, -4.5499e-01,  5.8835e-01,\n",
       "         -7.3908e-01, -8.5832e-18, -2.4319e-17,  1.8319e-16,  4.5466e-17,\n",
       "         -3.7120e-16, -2.4679e+00, -1.4089e-16, -1.8913e-16, -6.6085e-17,\n",
       "         -1.7418e-16,  1.6389e-16,  3.2307e+00,  1.7159e+00, -9.1631e-02,\n",
       "          2.4478e-16,  7.3486e-17, -7.7108e-17],\n",
       "        [-1.3197e-01, -6.8955e-02, -1.1641e-01, -5.4726e-01, -3.4791e-01,\n",
       "          8.2058e-01, -2.2645e-01, -4.2920e-01,  1.3557e+00, -1.1325e+00,\n",
       "         -1.0690e+00, -7.0711e-01, -1.3362e+00,  7.4444e-01, -4.5763e-01,\n",
       "          8.4294e-17, -1.6573e-01, -1.1752e+00,  2.1414e+00,  5.8835e-01,\n",
       "         -7.3908e-01,  1.8368e+00, -5.2161e-01,  7.4259e-01,  6.6380e-01,\n",
       "         -2.4494e-02,  1.0730e-01,  5.5293e-01,  7.4422e-02,  1.0034e+00,\n",
       "         -2.7960e-01, -2.5546e-01,  8.3924e-02,  8.5575e-01,  1.1650e+00,\n",
       "          9.7509e-01,  1.3979e+00,  1.0046e+00],\n",
       "        [ 1.0558e+00, -2.1092e-01, -1.6478e-01, -4.1911e-01, -8.6639e-01,\n",
       "         -1.2067e+00, -1.0279e+00, -1.1445e+00,  1.3557e+00, -1.1325e+00,\n",
       "          9.3541e-01, -7.0711e-01,  9.0591e-02,  7.4444e-01, -4.5763e-01,\n",
       "         -5.9050e-01, -1.2158e-01,  5.1516e-01, -4.5499e-01,  5.8835e-01,\n",
       "          4.9272e-01, -8.5832e-18, -2.4319e-17,  1.8319e-16,  4.5466e-17,\n",
       "         -3.7120e-16,  3.4668e-16, -1.4089e-16, -1.8913e-16, -6.6085e-17,\n",
       "         -1.7418e-16,  1.6389e-16, -1.0130e-16, -4.1766e-17, -1.8980e-16,\n",
       "          2.4478e-16,  7.3486e-17, -7.7108e-17],\n",
       "        [-5.6088e-01,  9.1940e-02,  5.9911e-01, -1.2786e-01, -7.8021e-01,\n",
       "         -1.2067e+00,  4.0710e-02, -4.2920e-01,  1.3557e+00, -1.1325e+00,\n",
       "         -1.0690e+00, -7.0711e-01,  9.0591e-02, -9.1867e-01, -4.5763e-01,\n",
       "         -1.1345e+00, -1.5284e-01,  5.1516e-01, -4.5499e-01, -2.1573e+00,\n",
       "         -7.3908e-01, -6.7841e-01, -6.2337e-01, -1.0401e+00, -9.6451e-01,\n",
       "         -2.4494e-02,  1.0730e-01, -1.0013e+00,  7.4422e-02, -9.5424e-01,\n",
       "         -1.1033e+00, -1.4817e+00, -1.0096e+00, -1.0039e+00, -1.3483e+00,\n",
       "         -9.1270e-01, -1.0933e+00, -1.7617e+00],\n",
       "        [-9.8979e-01,  6.9766e-01, -1.6478e-01, -3.5309e-01, -9.9427e-01,\n",
       "         -1.2067e+00,  2.1882e-01, -4.2920e-01, -7.3764e-01,  8.8298e-01,\n",
       "          9.3541e-01, -7.0711e-01,  5.6620e-01, -9.1867e-01,  1.9449e+00,\n",
       "         -1.0982e+00, -1.6595e-01,  5.1516e-01, -4.5499e-01, -7.8446e-01,\n",
       "         -7.3908e-01, -3.0909e-01, -3.3744e-01,  2.3168e-01, -1.3131e-04,\n",
       "         -2.4494e-02,  1.0730e-01, -6.5867e-01,  7.4422e-02,  4.4236e-01,\n",
       "         -1.3676e-01, -2.5546e-01,  1.2856e-01,  1.8888e-02, -9.1631e-02,\n",
       "         -1.3021e+00, -9.0396e-01, -3.7855e-01],\n",
       "        [ 1.0888e+00, -8.7884e-02, -9.9871e-01,  8.2746e-01, -6.7131e-02,\n",
       "         -1.9308e-01,  1.6437e+00,  1.0015e+00, -7.3764e-01,  8.8298e-01,\n",
       "          9.3541e-01, -7.0711e-01, -1.3362e+00, -9.1867e-01, -4.5763e-01,\n",
       "         -3.7291e-01, -1.6604e-01, -1.1752e+00, -9.7427e-01, -2.1573e+00,\n",
       "          4.9272e-01, -5.0024e-01, -5.8258e-01, -7.4590e-01, -6.4305e-01,\n",
       "         -2.4494e-02,  1.0730e-01, -7.6807e-01,  7.4422e-02, -6.3120e-01,\n",
       "         -6.7479e-01, -2.5546e-01, -6.3025e-01, -1.0039e+00, -1.3483e+00,\n",
       "         -5.5939e-01, -7.8534e-01, -3.7855e-01],\n",
       "        [ 1.9796e-01, -2.1092e-01, -1.0938e+00, -6.7153e-01,  9.3197e-03,\n",
       "          8.2058e-01,  1.3765e+00,  1.0015e+00, -7.3764e-01, -1.1325e+00,\n",
       "          9.3541e-01, -7.0711e-01,  1.0418e+00, -9.1867e-01, -4.5763e-01,\n",
       "          1.2953e+00, -1.6610e-01, -1.1752e+00,  1.1029e+00, -7.8446e-01,\n",
       "          1.7245e+00,  5.2015e-01, -2.0786e-01,  7.6857e-02, -1.4120e+00,\n",
       "         -2.3760e+00,  1.0730e-01,  2.2681e-01,  7.4422e-02,  2.7234e-01,\n",
       "          1.6082e-01, -2.5546e-01, -1.3925e-01,  2.0486e-01,  1.1650e+00,\n",
       "          8.0192e-02,  1.0308e-01, -3.7855e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.911634\n",
      "Epoch 10, Loss: 0.742672\n",
      "Epoch 20, Loss: 0.528279\n",
      "Epoch 30, Loss: 0.349997\n",
      "Epoch 40, Loss: 0.402448\n",
      "Epoch 50, Loss: 0.378883\n",
      "Epoch 60, Loss: 0.324763\n",
      "Epoch 70, Loss: 0.430325\n",
      "Epoch 80, Loss: 0.400720\n",
      "Epoch 90, Loss: 0.367245\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the training data and labels.\n",
    "\n",
    "input_dim = train_data.shape[1]  # Number of features\n",
    "model = PVEMClassifier(input_dim=input_dim, embedding_dim=128, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(train_data)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(logits, train_labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8095\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.73      0.89      0.80         9\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.81      0.82      0.81        21\n",
      "weighted avg       0.83      0.81      0.81        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data and labels.\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(test_data)\n",
    "    _, predicted = torch.max(logits, 1)\n",
    "\n",
    "accuracy = accuracy_score(test_labels.numpy(), predicted.numpy())\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels.numpy(), predicted.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pascal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
